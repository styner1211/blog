<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><meta name="google-site-verification" content="jYPfVliBMi2ENInqMBmjlQy7QaQYlNJFcz3CKbpQxiE"/><meta name="next-head-count" content="3"/><body><div id="__next" data-reactroot=""><div class="MainApp__GlobalContainer-sc-1rpcipa-0 krcVEB"><div class="MainApp__Container-sc-1rpcipa-1 ewsZwM"><div class="MainApp__HeaderContainer-sc-1rpcipa-2 fbkGGC"><div class="Header__Container-sc-13fiemu-0 dYSPYo"><div class="Header__Left-sc-13fiemu-1 hGyWUd"><div class="Header__MenuButtonItem-sc-13fiemu-5 fcVijG"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></div><div class="Header__LogoItem-sc-13fiemu-6 ekaHDe"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27100%27%20height=%2740%27/%3e"/></span><img alt="logo" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="logo" srcSet="/blog/barcode.png?imwidth=128 1x, /blog/barcode.png?imwidth=256 2x" src="/blog/barcode.png?imwidth=256" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div></div><div class="Header__Middle-sc-13fiemu-2 edgYtU"><div class="Header__HeaderItem-sc-13fiemu-9 eqLAjq"><a href="/blog/00.research" class="StyledLink__AnchorTag-sc-1001dlb-1 UrsbL">연구</a></div><div class="Header__HeaderItem-sc-13fiemu-9 eqLAjq"><a href="/blog/01.development" class="StyledLink__AnchorTag-sc-1001dlb-1 UrsbL">개발</a></div><div class="Header__HeaderItem-sc-13fiemu-9 eqLAjq"><a href="/blog/02.study" class="StyledLink__AnchorTag-sc-1001dlb-1 UrsbL">아무거나 정리</a></div><div class="Header__HeaderItem-sc-13fiemu-9 eqLAjq"><a href="/blog/03.project" class="StyledLink__AnchorTag-sc-1001dlb-1 UrsbL">토이 프로젝트</a></div></div><div class="Header__Right-sc-13fiemu-4 eJxZWF"></div></div></div><div class="MainApp__ContentContainer-sc-1rpcipa-3 dfELKT"><div class="SideBar__Container-sc-3wui5d-0 hhsZYw"></div><div class="path__Container-sc-ky1y75-0 gjyNUS"><div class="path__TopContainer-sc-ky1y75-1 fQsNxc"><div>오늘 방문자: <!-- -->1<!-- --> (총 방문자: <!-- -->54<!-- -->)</div></div><div class="path__BottomContainer-sc-ky1y75-2 grtMOo"><div class="MarkDownComponent__MarkDownContainer-sc-k3onaj-0 cpybIA"><div class="markdown"><h1>Singular Value Decomposition (SVD)</h1>
<blockquote>
<p>Singular Value Decomposition (이하 SVD)는 Eigendecomposition의 일반화된 형태이므로 먼저 Eigendecompositon에 대해 정리해 본다.</p>
</blockquote>
<h2>1. Eigendecomposition (고유값 분해)</h2>
<p>Eigendecomposition은 이름부터 뭔가 Eigenvector / Eigenvalue와 관련이 있을 것 같으니, 이 둘에 대해서 잠시 떠올려 보자.</p>
<h3>1.1. Eigenvector(<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">v</span></span></span></span></span>: 고유벡터) / Eigenvalue(<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span>: 고유값)</h3>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mi>v</mi><mo>=</mo><mi>λ</mi><mi>v</mi></mrow><annotation encoding="application/x-tex">Av = {\lambda}v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord"><span class="mord mathnormal">λ</span></span><span class="mord mathnormal" style="margin-right:0.03588em">v</span></span></span></span></span></div>
<p>n x n square matrix(정방 행렬) <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span>에 non-zero vecotr <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">v</span></span></span></span></span>를 곱했을 때의 결과가, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span>와 vector <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">v</span></span></span></span></span>의 곱과 같을 때, 이때 v를 eigenvector, 그리고 이에 대응되는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span>를 eigenvalue라 한다.</p>
<blockquote>
<p>어떤 정방 행렬 A를 eigenvector와 곱해도 eigenvector는 방향이 변하지 않고 scale만 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span>만큼 변한다.</p>
</blockquote>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>A</mi><mi>v</mi><mo>−</mo><mi>λ</mi><mi>v</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mo stretchy="false">(</mo><mi>A</mi><mo>−</mo><mi>λ</mi><mi>E</mi><mo stretchy="false">)</mo><mi>v</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
Av - {\lambda}v &amp;= 0
\\
(A - \lambda E)v &amp;= 0
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em"><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">λ</span></span><span class="mord mathnormal" style="margin-right:0.03588em">v</span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">λ</span><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.03588em">v</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em"><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord">0</span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p>이때, 위에서 v는 0이 아니라 했는데, 만약 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>−</mo><mi>λ</mi><mi>E</mi></mrow><annotation encoding="application/x-tex">A - {\lambda}E</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.7667em;vertical-align:-0.0833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord"><span class="mord mathnormal">λ</span></span><span class="mord mathnormal" style="margin-right:0.05764em">E</span></span></span></span></span>의 역행렬이 존재한다면, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>v</mi></mrow><annotation encoding="application/x-tex">v</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.03588em">v</span></span></span></span></span>는 항상 0이 되므로, non-zero eigenvector가 존재하기 위해서는 아래 식을 만족해야 한다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>d</mi><mi>e</mi><mi>t</mi><mo stretchy="false">(</mo><mi>A</mi><mo>−</mo><mi>λ</mi><mi>E</mi><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">det(A-\lambda E) = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">t</span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">λ</span><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span></span></div>
<p>이것을 행렬 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span>의 특성 방정식이라 부른다. 이것을 만족하는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span>를 구하는 것이 eigenvalue를 구하는 것이고, 이렇게 구한 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>λ</mi></mrow><annotation encoding="application/x-tex">\lambda</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">λ</span></span></span></span></span>를 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>A</mi><mo>−</mo><mi>λ</mi><mi>E</mi><mo stretchy="false">)</mo><mi>v</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">(A - \lambda E)v = 0</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal">λ</span><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">0</span></span></span></span></span>에 대입하여 계산하면 eigenvector를 구할 수 있다.</p>
<blockquote>
<p>어떤 행렬에 대해 고유값은 유일하게 결정되지만, 고유벡터는 유일하지 않다. (보통 크기를 1로 정규화한 벡터를 고유벡터로 사용한다)</p>
</blockquote>
<h3>1.2 대칭 행렬(symmetric matrix)과 고유값 분해</h3>
<blockquote>
<p>실수를 원소로 가지는 모든 대칭 행렬은 항상 고유값 분해가 가능하고, 이때 고유 벡터들은 서로 직교한다. (Spectral Therom)</p>
</blockquote>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mi>A</mi></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>Q</mi><mi mathvariant="normal">Λ</mi><msup><mi>Q</mi><mo lspace="0em" rspace="0em">⊺</mo></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>A</mi><mi>Q</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>Q</mi><mi mathvariant="normal">Λ</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
A &amp;= Q \Lambda Q^{\intercal}
\\
AQ &amp;= Q \Lambda
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em"><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">A</span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="mord mathnormal">Q</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em"><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">Q</span><span class="mord">Λ</span><span class="mord"><span class="mord mathnormal">Q</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord amsrm mtight">⊺</span></span></span></span></span></span></span></span></span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">Q</span><span class="mord">Λ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<figcaption align="center">
  <b>식1: eigendecomposition</b>
</figcaption>
<p>위 theorem에 따라 대칭 행렬 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span>는 위 식 1과 같이 서로 직교하는 (orthogonal) 고유 벡터 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span></span>를 갖는다.</p>
<p>이것이 가장 중요한 성질이라고 볼 수 있는데, 고유값 분해(eigendecomposition)에 의해 얻은 고유 벡터 고유 벡터 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span></span>가 어떤 새로운 차원에서의 축(axis)로서 기능을 할 수 있다는 것을 의미한다.
이해를 돕기 위해 (심혈을 기울여서) 그림을 그려 보자면 다음과 같다. (위 식 1과 비교해 보면서 생각해보자.)</p>
<img width="600" src="/blog//assets/research/svd/axis.JPG"/>
<figcaption align="center">
  <b>그림1: eigenvector의 역할</b>
</figcaption>
<p>즉, 고유값 분해로 구한, 고유 벡터로 이루어진 행렬을 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Q</mi></mrow><annotation encoding="application/x-tex">Q</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal">Q</span></span></span></span></span>의 각 열이 고유 벡터 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>v</mi><mn>1</mn></msup></mrow><annotation encoding="application/x-tex">v^1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span>, 고유 벡터<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>v</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">v^2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8141em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8141em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span></span></span></span></span>인데, 앞서 설명한 therem에 따라 각 벡터는 서로 orthgonal하기 때문에, 새로운 기저 공간에서의 축(axis)으로 역할을 할 수 있는 것이다. (위 그림 1에서 빨간색 축)</p>
<p>그리고 행렬 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span>에 있던 정보(좌표)들은 새로운 공간에서는 아래와 같은 좌표에 위치하는 생각 할 수 있다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><msup><mi>a</mi><mn>1</mn></msup><mo separator="true">,</mo><msup><mi>a</mi><mn>2</mn></msup><mo stretchy="false">)</mo><mo>→</mo><mo stretchy="false">(</mo><mi mathvariant="normal">∣</mi><msub><mi>a</mi><mn>1</mn></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msup><mi>v</mi><mn>1</mn></msup><mi mathvariant="normal">∣</mi><mi>c</mi><mi>o</mi><mi>s</mi><mi>θ</mi><mo separator="true">,</mo><mi mathvariant="normal">∣</mi><msub><mi>a</mi><mn>2</mn></msub><mi mathvariant="normal">∣</mi><mi mathvariant="normal">∣</mi><msup><mi>v</mi><mn>2</mn></msup><mi mathvariant="normal">∣</mi><mi>c</mi><mi>o</mi><mi>s</mi><mi>θ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(a^1, a^2) \to (|a_1||v^1|cos\theta, |a_2||v^2|cos\theta)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">→</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1.1141em;vertical-align:-0.25em"></span><span class="mopen">(</span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal">cos</span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">∣</span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∣∣</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal">cos</span><span class="mord mathnormal" style="margin-right:0.02778em">θ</span><span class="mclose">)</span></span></span></span></span></div>
<p>지금까지 설명한 eigendecomposition에 대해 어느 정도 이해했다면, 이어질 Singular Value Decomposition에 대한 부분은 사실 다 이해한 것이나 다름 없다.</p>
<h2>2. Singular Value Decomposition (특이값 분해)</h2>
<blockquote>
<p>특이값 분해는 고유값 분해의 좀 더 일반화된 개념이다.</p>
</blockquote>
<p>앞서 고유값 분해는 반드시 정방 행렬이어야만 했다. 하지만 특이값 분해는 정방 행렬일 필요 없이 m x n 행렬 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span>를 다음과 같이 표현 한다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>A</mi><mo>=</mo><mi>U</mi><mi>D</mi><msup><mi>V</mi><mo lspace="0em" rspace="0em">⊺</mo></msup></mrow><annotation encoding="application/x-tex">A = UDV^{\intercal}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.7144em"></span><span class="mord mathnormal" style="margin-right:0.10903em">U</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord"><span class="mord mathnormal" style="margin-right:0.22222em">V</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord amsrm mtight">⊺</span></span></span></span></span></span></span></span></span></span></span></span></span></div>
<figcaption align="center">
  <b>식2: singular value decomposition</b>
</figcaption>
<p>그리고 다음은 같은 Singular Vector Decomposition의 중요한 성질이 있다.</p>
<ul>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span>는 m x n matrix (정방행렬 아님)</li>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">U</span></span></span></span></span>는 m x m orthogonal matrix 이고, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><msup><mi>A</mi><mo lspace="0em" rspace="0em">⊺</mo></msup></mrow><annotation encoding="application/x-tex">AA^{\intercal}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord amsrm mtight">⊺</span></span></span></span></span></span></span></span></span></span></span></span></span>의 eigenvector로 이루어진 행렬이고, 이것이 singular vector 라는 것</li>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span></span>는 m x n matrix 이고, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mo lspace="0em" rspace="0em">⊺</mo></msup><mi>A</mi></mrow><annotation encoding="application/x-tex">A^{\intercal}A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord amsrm mtight">⊺</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">A</span></span></span></span></span>의 eigenvalue의 제곱근으로 이루어진 대각 행렬이고, 이것이 singular value 라는 것</li>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span></span>는 n x m orthogonal matrix 이고, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mo lspace="0em" rspace="0em">⊺</mo></msup><mi>A</mi></mrow><annotation encoding="application/x-tex">A^{\intercal}A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord amsrm mtight">⊺</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">A</span></span></span></span></span>의 eigenvector로 이루어진 행렬이고, 이것이 singular vector라는 것</li>
</ul>
<p>이것은 다음과 같은 식을 통해 위 성질이 타당하다라는 결론을 얻을 수 있다.</p>
<p>왜냐하면 임의의 행렬 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span>가 정방행렬이 아니더라도 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><msup><mi>A</mi><mo lspace="0em" rspace="0em">⊺</mo></msup></mrow><annotation encoding="application/x-tex">AA^{\intercal}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord amsrm mtight">⊺</span></span></span></span></span></span></span></span></span></span></span></span></span> 혹은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>A</mi><mo lspace="0em" rspace="0em">⊺</mo></msup><mi>A</mi></mrow><annotation encoding="application/x-tex">A^{\intercal}A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord"><span class="mord mathnormal">A</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.6644em"><span style="top:-3.063em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord amsrm mtight">⊺</span></span></span></span></span></span></span></span></span><span class="mord mathnormal">A</span></span></span></span></span>는 정방 행렬이 되고 앞서 설명한 것처럼 고유 벡터를 가지게 된다.
또한 orthgonal matrix는, 자신을 transpose 시키면 자신의 역행렬이 되는 성질을 가지고 있고, 각 행벡터 혹은 각 열벡터가 서로 orthogonal 하기 때문에 위와 같은 설명이 가능해 진다.</p>
<img width="600" src="/blog//assets/research/svd/svd.JPG"/>
<figcaption align="center">
  <b>그림2: Singular Vector Decomposition</b>
</figcaption>
<blockquote>
<p>특이값 분해에서는 특이값(singular value)의 크기에 따라 상위 N개와 대응하는 차원만을 활용하여 저차원 벡터로 임베딩 하는 효과를 누리게 된다</p>
</blockquote>
<p>특이값 분해는 위 그림의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span> 행렬을 어떻게 정의하느냐에 활용도가 무궁무진하다.</p>
<p>생각나는 것 몇가지만 적어보자면,</p>
<ul>
<li>정보 검색에서는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span>를 Term X Document 행렬로 보고 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>U</mi></mrow><annotation encoding="application/x-tex">U</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.10903em">U</span></span></span></span></span>의 각 행과 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span></span>의 각 열을 Term Vector 또는 Document Vector로 활용하여 문서의 유사도 측정에 활용</li>
<li>문서 요약에서는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span>를 Term X Document 행렬로 보고 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>V</mi></mrow><annotation encoding="application/x-tex">V</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.22222em">V</span></span></span></span></span>에서 나타난 Sentence Embedding의 요소 값과 대응하는 singular vector를 활용하여 문장에서 나타나는 특정 Concept의 중요도를 반영하여 문장의 중요도를 측정</li>
<li>추천 시스템에서는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal">A</span></span></span></span></span>를 User X Item 행렬로 이루어진 Rating 값으로 보고 특정 User가 관심이 있을 법한 Item을 선정 한다던지, 특정 Item이 타게팅 하면 좋을 User를 선별 한다던지에 활용</li>
</ul></div></div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"mappings":[{"header":{"label":"연구","path":"00.research","md":"","preview":true,"sub":[{"label":"베이지안 추론","path":"bayesian-inference","md":"","preview":true,"sub":[{"label":"Coin Tossing","path":"coin-tossing","md":"","preview":true,"sub":[],"img":"/assets/research/bayesian-inference/coin-tossing/coin-tossing.jpg","snippet":"동전을 던졌을 때, 앞면이 나올 확률을 데이터에 기반하여 추정해보자","depth":2},{"label":"Curve Fitting","path":"curve-fitting","md":"","preview":true,"sub":[],"img":"/assets/research/bayesian-inference/curve-fitting/curve-fitting.JPG","snippet":"가지 중요한 개념을 설명하기에 앞서, 간단한 회귀(Regression) 문제를 소개해 보도록 하겠다.","depth":2},{"label":"Gibbs Sampling","path":"gibbs-sampling","md":"","preview":true,"sub":[],"img":"/assets/study/inverse-transform-sampling/Inverse_Transform_Sampling_Example.gif","snippet":"Gibbs Sampling을 구현하기위해 사용한 Inverse Transform Sampling 기법을 소개하면서 실질적인 구현 방법을 먼저 소개하고, 이론적인 배경은 나중에 업데이트 할 예정이다.","depth":2},{"label":"Variational Inference","path":"variational-inference","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Inference는 [Bayeisan Inference](/docs/research/bayesian-inference)에서 적용되는 테크닉으로 개인적으로는 상당히 공부하기 어려웠던 것 중 하나여서 시간을 내어 정리해 보려고 한다.","depth":2}],"img":"/barcode.png","snippet":"Inference를 설명하기에 앞서 다음과 같은 순서로 각 개념을 이해하는 것이 중요하다.","depth":1},{"label":"가우시안 혼합 모델","path":"gaussian-mixture-model","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"K-means Clustering","path":"k-means","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"K-means 알고리즘은 Gaussian Mixture Model의 특별한 경우이다. 그리고 EM 알고리즘의 Expectation 단계와 Maximazation 단계를 거쳐 학습하는 과정을 거친다.","depth":1},{"label":"Multi-Armed Bandit","path":"multi-armed-bandit","md":"","preview":true,"sub":[],"img":"/assets/research/multi-armed-bandit/mab.JPG","snippet":"여러대의 슬롯 머신이 있다고 하자. 그리고 일확천금을 위해서 어떤 사람이 슬롯 머신을 여기 저기서 당기고 있다. 이때 이 사람이 수익을 극대화 하는 방법이 있을까?","depth":1},{"label":"PageRank","path":"pagerank","md":"","preview":true,"sub":[],"img":"/assets/research/pagerank/pagerank.png","snippet":"상당히 직관적이고 간단하게 이해할 수 있는 개념이지만 그 이면을 들여다 보면 공부할 만한 사실들이 상당히 많이 있다. 그 중 중요하다고 생각하는 부분들에 대해서 소개하려고 한다.","depth":1},{"label":"추천 시스템","path":"recommendation-system","md":"","preview":true,"sub":[{"label":"컨텐츠 기반 알고리즘","path":"contents","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Matrix Factorization","path":"matrix-factorization","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Factorization은 추천 시스템에서 협업 필터링(Collaborative Filtering) 알고리즘에 속한다. 아이디어는 상당히 간단한데 User와 Item을 행과 열로 가진 Matrix 분해햐여 User와 Item을 low dimensional latent space에 사상 시키는 방법이다. 이를 위해 아랴와 같이 크게 두가지 방식으로 User-Item Matrix를 Decomposition 할 수 있다.","depth":2},{"label":"모델 기반 협업 필터링","path":"model","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"neighbor","path":"neighbor","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"Stochastic Process","path":"stochastic-process","md":"","preview":true,"sub":[{"label":"디리클레 프로세스","path":"dirichlet-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"가우시안 프로세스","path":"gaussian-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"혹스 프로세스","path":"hawkes-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"포아송 프로세스","path":"poisson-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"Stochastic Process란, Random Variable(확률 변수) 혹은 function의 collection을 의미한다.","depth":1},{"label":"Singular Value Decomposition","path":"svd","md":"","preview":true,"sub":[],"img":"/assets/research/svd/axis.JPG","snippet":"Singular Value Decomposition (이하 SVD)는 Eigendecomposition의 일반화된 형태이므로 먼저 Eigendecompositon에 대해 정리해 본다.","depth":1},{"label":"Topic Model","path":"topic-modeling","md":"","preview":true,"sub":[{"label":"Adversarial-neural Event Model","path":"aem","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Correlated Topic Model","path":"ctm","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Gaussain LDA","path":"glda","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Hierarchical Dirichlet Process","path":"hdp","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"LDA의 Non-parametric 버전으로 토픽 갯수 K를 지정하지 않아도 되는 더 일반적인 모델","depth":2},{"label":"Latent Dirichlet Allocation","path":"lda","md":"","preview":true,"sub":[],"img":"/assets/research/topic_modeling/lda/dist_desc.JPG","snippet":"LDA는 임의의 문서를 K개의 토픽 분포로 표현하고, 각 토픽은 V개의 단어 분포로 표현하는 모델이다.","depth":2},{"label":"Latent Event Model","path":"lem","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"토픽 모델이 뭔지 정리해보자","depth":1},{"label":"Variational AutoEncoder","path":"variational-autoencoder","md":"","preview":true,"sub":[],"img":"/assets/research/variational-autoencoder/ae-vae.png","snippet":"","depth":1}],"img":"/barcode.png","snippet":"공부했던 것들 중에, 생각할 것들이 많았던 것들을 정리하고 있다.","depth":0},"side_bar":[{"label":"베이지안 추론","path":"bayesian-inference","md":"","preview":true,"sub":[{"label":"Coin Tossing","path":"coin-tossing","md":"","preview":true,"sub":[],"img":"/assets/research/bayesian-inference/coin-tossing/coin-tossing.jpg","snippet":"동전을 던졌을 때, 앞면이 나올 확률을 데이터에 기반하여 추정해보자","depth":2},{"label":"Curve Fitting","path":"curve-fitting","md":"","preview":true,"sub":[],"img":"/assets/research/bayesian-inference/curve-fitting/curve-fitting.JPG","snippet":"가지 중요한 개념을 설명하기에 앞서, 간단한 회귀(Regression) 문제를 소개해 보도록 하겠다.","depth":2},{"label":"Gibbs Sampling","path":"gibbs-sampling","md":"","preview":true,"sub":[],"img":"/assets/study/inverse-transform-sampling/Inverse_Transform_Sampling_Example.gif","snippet":"Gibbs Sampling을 구현하기위해 사용한 Inverse Transform Sampling 기법을 소개하면서 실질적인 구현 방법을 먼저 소개하고, 이론적인 배경은 나중에 업데이트 할 예정이다.","depth":2},{"label":"Variational Inference","path":"variational-inference","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Inference는 [Bayeisan Inference](/docs/research/bayesian-inference)에서 적용되는 테크닉으로 개인적으로는 상당히 공부하기 어려웠던 것 중 하나여서 시간을 내어 정리해 보려고 한다.","depth":2}],"img":"/barcode.png","snippet":"Inference를 설명하기에 앞서 다음과 같은 순서로 각 개념을 이해하는 것이 중요하다.","depth":1},{"label":"가우시안 혼합 모델","path":"gaussian-mixture-model","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"K-means Clustering","path":"k-means","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"K-means 알고리즘은 Gaussian Mixture Model의 특별한 경우이다. 그리고 EM 알고리즘의 Expectation 단계와 Maximazation 단계를 거쳐 학습하는 과정을 거친다.","depth":1},{"label":"Multi-Armed Bandit","path":"multi-armed-bandit","md":"","preview":true,"sub":[],"img":"/assets/research/multi-armed-bandit/mab.JPG","snippet":"여러대의 슬롯 머신이 있다고 하자. 그리고 일확천금을 위해서 어떤 사람이 슬롯 머신을 여기 저기서 당기고 있다. 이때 이 사람이 수익을 극대화 하는 방법이 있을까?","depth":1},{"label":"PageRank","path":"pagerank","md":"","preview":true,"sub":[],"img":"/assets/research/pagerank/pagerank.png","snippet":"상당히 직관적이고 간단하게 이해할 수 있는 개념이지만 그 이면을 들여다 보면 공부할 만한 사실들이 상당히 많이 있다. 그 중 중요하다고 생각하는 부분들에 대해서 소개하려고 한다.","depth":1},{"label":"추천 시스템","path":"recommendation-system","md":"","preview":true,"sub":[{"label":"컨텐츠 기반 알고리즘","path":"contents","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Matrix Factorization","path":"matrix-factorization","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Factorization은 추천 시스템에서 협업 필터링(Collaborative Filtering) 알고리즘에 속한다. 아이디어는 상당히 간단한데 User와 Item을 행과 열로 가진 Matrix 분해햐여 User와 Item을 low dimensional latent space에 사상 시키는 방법이다. 이를 위해 아랴와 같이 크게 두가지 방식으로 User-Item Matrix를 Decomposition 할 수 있다.","depth":2},{"label":"모델 기반 협업 필터링","path":"model","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"neighbor","path":"neighbor","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"Stochastic Process","path":"stochastic-process","md":"","preview":true,"sub":[{"label":"디리클레 프로세스","path":"dirichlet-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"가우시안 프로세스","path":"gaussian-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"혹스 프로세스","path":"hawkes-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"포아송 프로세스","path":"poisson-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"Stochastic Process란, Random Variable(확률 변수) 혹은 function의 collection을 의미한다.","depth":1},{"label":"Singular Value Decomposition","path":"svd","md":"","preview":true,"sub":[],"img":"/assets/research/svd/axis.JPG","snippet":"Singular Value Decomposition (이하 SVD)는 Eigendecomposition의 일반화된 형태이므로 먼저 Eigendecompositon에 대해 정리해 본다.","depth":1},{"label":"Topic Model","path":"topic-modeling","md":"","preview":true,"sub":[{"label":"Adversarial-neural Event Model","path":"aem","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Correlated Topic Model","path":"ctm","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Gaussain LDA","path":"glda","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Hierarchical Dirichlet Process","path":"hdp","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"LDA의 Non-parametric 버전으로 토픽 갯수 K를 지정하지 않아도 되는 더 일반적인 모델","depth":2},{"label":"Latent Dirichlet Allocation","path":"lda","md":"","preview":true,"sub":[],"img":"/assets/research/topic_modeling/lda/dist_desc.JPG","snippet":"LDA는 임의의 문서를 K개의 토픽 분포로 표현하고, 각 토픽은 V개의 단어 분포로 표현하는 모델이다.","depth":2},{"label":"Latent Event Model","path":"lem","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"토픽 모델이 뭔지 정리해보자","depth":1},{"label":"Variational AutoEncoder","path":"variational-autoencoder","md":"","preview":true,"sub":[],"img":"/assets/research/variational-autoencoder/ae-vae.png","snippet":"","depth":1}]},{"header":{"label":"개발","path":"01.development","md":"","preview":true,"sub":[{"label":"엘라스틱서치","path":"elasticsearch","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"사용했던 것들을 정리해보자.","depth":1},{"label":"개발 환경 구축","path":"env","md":"","preview":true,"sub":[{"label":"code-server","path":"code-server","md":"","preview":true,"sub":[],"img":"/assets/development/env/code-server/code-server.png","snippet":"+ ubuntu 20.04","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"명령어 기록","path":"etc","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"sh","depth":1},{"label":"하둡","path":"hadoop","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"java","path":"java","md":"","preview":true,"sub":[{"label":"자바의 비동기 기술","path":"async","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Future","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"쿠버네티스","path":"k8s","md":"","preview":true,"sub":[{"label":"쿠버네티스 설치","path":"installation","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"집에 놀고 있는 리눅스 머신에 K8S를 설치 해보자","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"메시지 브로커","path":"kafka","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"보내고, 처리하고, 삭제한다.","depth":1},{"label":"코틀린","path":"kotlin","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"루씬","path":"lucene","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"거의 Elasticsearch를 이용해서 프로젝트를 진행하지만, 검색이 필요한 경우 Lucene을 이용해서 개발하는 경우가 많았던 것 같다. JAVA에 Lucence 의존성만 추가하면 뭔가 가볍게 시작할 수 있었기 때문인데 점점 기능이 복잡해 질 수록 Elasticsearch가 얼마나 잘 만들어져 있는 것인가를 느끼고 있다. 그래도 Elasticsearch는 Lucence을 가져다 쓰는거니까 먼저 간단한 것 부터 정리해 볼 계획이다.","depth":1},{"label":"리액트","path":"react","md":"","preview":true,"sub":[{"label":"package.json","path":"package-json","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"dependencies vs devDependencies","depth":2},{"label":"react-snap으로 정적페이지 빌드","path":"react-snap","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Basic usage with create-react-app","depth":2},{"label":"GitHub Pages에 SPA","path":"spa-github-pages","md":"","preview":true,"sub":[],"img":"/assets/development/react/spa-github-pages/github-pages-404.JPG","snippet":"1. 문제 상황","depth":2}],"img":"/assets/development/react/react-app.png","snippet":"React 개발 환경 구축","depth":1},{"label":"스프링 부트","path":"spring-boot","md":"","preview":true,"sub":[{"label":"Spring Boot에서 HTTPS 적용","path":"https","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Certificate 만들기","depth":2},{"label":"Maven에서 Spring Boot 설정","path":"maven-support","md":"","preview":true,"sub":[],"img":"/assets/development/spring-boot/maven-support/multi-module.JPG","snippet":"Maven multi-module 프로젝트에서 Spring Boot Application을 Maven Dependency로 Import하기","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"웹플럭스","path":"webflux","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}],"img":"/barcode.png","snippet":"","depth":0},"side_bar":[{"label":"엘라스틱서치","path":"elasticsearch","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"사용했던 것들을 정리해보자.","depth":1},{"label":"개발 환경 구축","path":"env","md":"","preview":true,"sub":[{"label":"code-server","path":"code-server","md":"","preview":true,"sub":[],"img":"/assets/development/env/code-server/code-server.png","snippet":"+ ubuntu 20.04","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"명령어 기록","path":"etc","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"sh","depth":1},{"label":"하둡","path":"hadoop","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"java","path":"java","md":"","preview":true,"sub":[{"label":"자바의 비동기 기술","path":"async","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Future","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"쿠버네티스","path":"k8s","md":"","preview":true,"sub":[{"label":"쿠버네티스 설치","path":"installation","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"집에 놀고 있는 리눅스 머신에 K8S를 설치 해보자","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"메시지 브로커","path":"kafka","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"보내고, 처리하고, 삭제한다.","depth":1},{"label":"코틀린","path":"kotlin","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"루씬","path":"lucene","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"거의 Elasticsearch를 이용해서 프로젝트를 진행하지만, 검색이 필요한 경우 Lucene을 이용해서 개발하는 경우가 많았던 것 같다. JAVA에 Lucence 의존성만 추가하면 뭔가 가볍게 시작할 수 있었기 때문인데 점점 기능이 복잡해 질 수록 Elasticsearch가 얼마나 잘 만들어져 있는 것인가를 느끼고 있다. 그래도 Elasticsearch는 Lucence을 가져다 쓰는거니까 먼저 간단한 것 부터 정리해 볼 계획이다.","depth":1},{"label":"리액트","path":"react","md":"","preview":true,"sub":[{"label":"package.json","path":"package-json","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"dependencies vs devDependencies","depth":2},{"label":"react-snap으로 정적페이지 빌드","path":"react-snap","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Basic usage with create-react-app","depth":2},{"label":"GitHub Pages에 SPA","path":"spa-github-pages","md":"","preview":true,"sub":[],"img":"/assets/development/react/spa-github-pages/github-pages-404.JPG","snippet":"1. 문제 상황","depth":2}],"img":"/assets/development/react/react-app.png","snippet":"React 개발 환경 구축","depth":1},{"label":"스프링 부트","path":"spring-boot","md":"","preview":true,"sub":[{"label":"Spring Boot에서 HTTPS 적용","path":"https","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Certificate 만들기","depth":2},{"label":"Maven에서 Spring Boot 설정","path":"maven-support","md":"","preview":true,"sub":[],"img":"/assets/development/spring-boot/maven-support/multi-module.JPG","snippet":"Maven multi-module 프로젝트에서 Spring Boot Application을 Maven Dependency로 Import하기","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"웹플럭스","path":"webflux","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}]},{"header":{"label":"아무거나 정리","path":"02.study","md":"","preview":true,"sub":[{"label":"Chi-Square Test","path":"chi-square-test","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"검정은 하나 이상의 카테고리에서 관측된 빈도와 기대되는 빈도가 통계적으로 유의하게 다른지 검증하는 기법으로, 카이 제곱 분포에 기초한 통계적 가설 검정 방법이다.","depth":1},{"label":"HTTPS와 공개 키 암호 방식","path":"crypto","md":"","preview":true,"sub":[],"img":"/assets/study/crypto/https.png","snippet":"그린 그림인지 모르겠지만 가장 쉽게 잘 설명해주신 것 같다.","depth":1},{"label":"NumPy","path":"numpy","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"np.array","depth":1},{"label":"P-value","path":"p-value","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"pandas","path":"pandas","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"PyTorch","path":"pytorch","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}],"img":"/barcode.png","snippet":"궁금해서 찾아본 것, 알고 있었는데 까먹고 있었던 것, 생각 날 때마다 정리해보자.","depth":0},"side_bar":[{"label":"Chi-Square Test","path":"chi-square-test","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"검정은 하나 이상의 카테고리에서 관측된 빈도와 기대되는 빈도가 통계적으로 유의하게 다른지 검증하는 기법으로, 카이 제곱 분포에 기초한 통계적 가설 검정 방법이다.","depth":1},{"label":"HTTPS와 공개 키 암호 방식","path":"crypto","md":"","preview":true,"sub":[],"img":"/assets/study/crypto/https.png","snippet":"그린 그림인지 모르겠지만 가장 쉽게 잘 설명해주신 것 같다.","depth":1},{"label":"NumPy","path":"numpy","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"np.array","depth":1},{"label":"P-value","path":"p-value","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"pandas","path":"pandas","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"PyTorch","path":"pytorch","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}]},{"header":{"label":"토이 프로젝트","path":"03.project","md":"","preview":true,"sub":[{"label":"CNN 기반 형태소 분석기","path":"cnn-morph","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}],"img":"/barcode.png","snippet":"","depth":0},"side_bar":[{"label":"CNN 기반 형태소 분석기","path":"cnn-morph","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}]}],"visitors":{"today":1,"total":54},"post":"# Singular Value Decomposition (SVD)\r\n\r\n\u003e Singular Value Decomposition (이하 SVD)는 Eigendecomposition의 일반화된 형태이므로 먼저 Eigendecompositon에 대해 정리해 본다.\r\n\r\n## 1. Eigendecomposition (고유값 분해)\r\n\r\nEigendecomposition은 이름부터 뭔가 Eigenvector / Eigenvalue와 관련이 있을 것 같으니, 이 둘에 대해서 잠시 떠올려 보자.\r\n\r\n### 1.1. Eigenvector($$v$$: 고유벡터) / Eigenvalue($$\\lambda$$: 고유값)\r\n\r\n$$\r\nAv = {\\lambda}v\r\n$$\r\n\r\nn x n square matrix(정방 행렬) $$A$$에 non-zero vecotr $$v$$를 곱했을 때의 결과가, $$\\lambda$$와 vector $$v$$의 곱과 같을 때, 이때 v를 eigenvector, 그리고 이에 대응되는 $$\\lambda$$를 eigenvalue라 한다.\r\n\r\n\u003e 어떤 정방 행렬 A를 eigenvector와 곱해도 eigenvector는 방향이 변하지 않고 scale만 $$\\lambda$$만큼 변한다.\r\n\r\n$$\r\n\\begin{aligned}\r\nAv - {\\lambda}v \u0026= 0\r\n\\\\\r\n(A - \\lambda E)v \u0026= 0\r\n\\end{aligned}\r\n$$\r\n\r\n이때, 위에서 v는 0이 아니라 했는데, 만약 $$A - {\\lambda}E$$의 역행렬이 존재한다면, $$v$$는 항상 0이 되므로, non-zero eigenvector가 존재하기 위해서는 아래 식을 만족해야 한다.\r\n\r\n$$\r\ndet(A-\\lambda E) = 0\r\n$$\r\n\r\n이것을 행렬 $$A$$의 특성 방정식이라 부른다. 이것을 만족하는 $$\\lambda$$를 구하는 것이 eigenvalue를 구하는 것이고, 이렇게 구한 $$\\lambda$$를 $$(A - \\lambda E)v = 0$$에 대입하여 계산하면 eigenvector를 구할 수 있다.\r\n\r\n\u003e 어떤 행렬에 대해 고유값은 유일하게 결정되지만, 고유벡터는 유일하지 않다. (보통 크기를 1로 정규화한 벡터를 고유벡터로 사용한다)\r\n\r\n### 1.2 대칭 행렬(symmetric matrix)과 고유값 분해\r\n\r\n\u003e 실수를 원소로 가지는 모든 대칭 행렬은 항상 고유값 분해가 가능하고, 이때 고유 벡터들은 서로 직교한다. (Spectral Therom)\r\n\r\n$$\r\n\\begin{aligned}\r\nA \u0026= Q \\Lambda Q^{\\intercal}\r\n\\\\\r\nAQ \u0026= Q \\Lambda\r\n\\end{aligned}\r\n$$\r\n\r\n\u003cfigcaption align=\"center\"\u003e\r\n  \u003cb\u003e식1: eigendecomposition\u003c/b\u003e\r\n\u003c/figcaption\u003e\r\n\r\n위 theorem에 따라 대칭 행렬 $$A$$는 위 식 1과 같이 서로 직교하는 (orthogonal) 고유 벡터 $$Q$$를 갖는다.\r\n\r\n이것이 가장 중요한 성질이라고 볼 수 있는데, 고유값 분해(eigendecomposition)에 의해 얻은 고유 벡터 고유 벡터 $$Q$$가 어떤 새로운 차원에서의 축(axis)로서 기능을 할 수 있다는 것을 의미한다.\r\n이해를 돕기 위해 (심혈을 기울여서) 그림을 그려 보자면 다음과 같다. (위 식 1과 비교해 보면서 생각해보자.)\r\n\r\n\u003cimg width=\"600\" src=\"/assets/research/svd/axis.JPG\" /\u003e\r\n\u003cfigcaption align=\"center\"\u003e\r\n  \u003cb\u003e그림1: eigenvector의 역할\u003c/b\u003e\r\n\u003c/figcaption\u003e\r\n\r\n즉, 고유값 분해로 구한, 고유 벡터로 이루어진 행렬을 $$Q$$의 각 열이 고유 벡터 $$v^1$$, 고유 벡터$$v^2$$인데, 앞서 설명한 therem에 따라 각 벡터는 서로 orthgonal하기 때문에, 새로운 기저 공간에서의 축(axis)으로 역할을 할 수 있는 것이다. (위 그림 1에서 빨간색 축)\r\n\r\n그리고 행렬 $$A$$에 있던 정보(좌표)들은 새로운 공간에서는 아래와 같은 좌표에 위치하는 생각 할 수 있다.\r\n\r\n$$\r\n(a^1, a^2) \\to (|a_1||v^1|cos\\theta, |a_2||v^2|cos\\theta)\r\n$$\r\n\r\n지금까지 설명한 eigendecomposition에 대해 어느 정도 이해했다면, 이어질 Singular Value Decomposition에 대한 부분은 사실 다 이해한 것이나 다름 없다.\r\n\r\n## 2. Singular Value Decomposition (특이값 분해)\r\n\r\n\u003e 특이값 분해는 고유값 분해의 좀 더 일반화된 개념이다.\r\n\r\n앞서 고유값 분해는 반드시 정방 행렬이어야만 했다. 하지만 특이값 분해는 정방 행렬일 필요 없이 m x n 행렬 $$A$$를 다음과 같이 표현 한다.\r\n\r\n$$\r\nA = UDV^{\\intercal}\r\n$$\r\n\r\n\u003cfigcaption align=\"center\"\u003e\r\n  \u003cb\u003e식2: singular value decomposition\u003c/b\u003e\r\n\u003c/figcaption\u003e\r\n\r\n그리고 다음은 같은 Singular Vector Decomposition의 중요한 성질이 있다.\r\n\r\n- $$A$$는 m x n matrix (정방행렬 아님)\r\n- $$U$$는 m x m orthogonal matrix 이고, $$AA^{\\intercal}$$의 eigenvector로 이루어진 행렬이고, 이것이 singular vector 라는 것\r\n- $$D$$는 m x n matrix 이고, $$A^{\\intercal}A$$의 eigenvalue의 제곱근으로 이루어진 대각 행렬이고, 이것이 singular value 라는 것\r\n- $$V$$는 n x m orthogonal matrix 이고, $$A^{\\intercal}A$$의 eigenvector로 이루어진 행렬이고, 이것이 singular vector라는 것\r\n\r\n이것은 다음과 같은 식을 통해 위 성질이 타당하다라는 결론을 얻을 수 있다.\r\n\r\n왜냐하면 임의의 행렬 $$A$$가 정방행렬이 아니더라도 $$AA^{\\intercal}$$ 혹은 $$A^{\\intercal}A$$는 정방 행렬이 되고 앞서 설명한 것처럼 고유 벡터를 가지게 된다.\r\n또한 orthgonal matrix는, 자신을 transpose 시키면 자신의 역행렬이 되는 성질을 가지고 있고, 각 행벡터 혹은 각 열벡터가 서로 orthogonal 하기 때문에 위와 같은 설명이 가능해 진다.\r\n\r\n\u003cimg width=\"600\" src=\"/assets/research/svd/svd.JPG\" /\u003e\r\n\u003cfigcaption align=\"center\"\u003e\r\n  \u003cb\u003e그림2: Singular Vector Decomposition\u003c/b\u003e\r\n\u003c/figcaption\u003e\r\n\r\n\u003e 특이값 분해에서는 특이값(singular value)의 크기에 따라 상위 N개와 대응하는 차원만을 활용하여 저차원 벡터로 임베딩 하는 효과를 누리게 된다\r\n\r\n특이값 분해는 위 그림의 $$A$$ 행렬을 어떻게 정의하느냐에 활용도가 무궁무진하다.\r\n\r\n생각나는 것 몇가지만 적어보자면,\r\n\r\n- 정보 검색에서는 $$A$$를 Term X Document 행렬로 보고 $$U$$의 각 행과 $$V$$의 각 열을 Term Vector 또는 Document Vector로 활용하여 문서의 유사도 측정에 활용\r\n- 문서 요약에서는 $$A$$를 Term X Document 행렬로 보고 $$V$$에서 나타난 Sentence Embedding의 요소 값과 대응하는 singular vector를 활용하여 문장에서 나타나는 특정 Concept의 중요도를 반영하여 문장의 중요도를 측정\r\n- 추천 시스템에서는 $$A$$를 User X Item 행렬로 이루어진 Rating 값으로 보고 특정 User가 관심이 있을 법한 Item을 선정 한다던지, 특정 Item이 타게팅 하면 좋을 User를 선별 한다던지에 활용\r\n","path":"00.research/svd"},"__N_SSG":true},"page":"/[[...path]]","query":{"path":["00.research","svd"]},"buildId":"xKGKkOYAc8R8vOdgxDDZf","assetPrefix":"/blog","isFallback":false,"gsp":true,"appGip":true,"scriptLoader":[]}</script></body><link rel="preload" href="/blog/_next/static/css/990b0c1dfde9f715.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/990b0c1dfde9f715.css" data-n-g=""/><link rel="preload" href="/blog/_next/static/css/c4f4fac9cc925550.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/c4f4fac9cc925550.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/blog/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/blog/_next/static/chunks/webpack-5f931f2fb596b881.js" defer=""></script><script src="/blog/_next/static/chunks/framework-bb5c596eafb42b22.js" defer=""></script><script src="/blog/_next/static/chunks/main-9ce13651fe56a6de.js" defer=""></script><script src="/blog/_next/static/chunks/pages/_app-c6817dd1feeeea1c.js" defer=""></script><script src="/blog/_next/static/chunks/175675d1-f160d4a5df49f5d3.js" defer=""></script><script src="/blog/_next/static/chunks/pages/%5B%5B...path%5D%5D-0fce9fdd45369aef.js" defer=""></script><script src="/blog/_next/static/xKGKkOYAc8R8vOdgxDDZf/_buildManifest.js" defer=""></script><script src="/blog/_next/static/xKGKkOYAc8R8vOdgxDDZf/_ssgManifest.js" defer=""></script><script src="/blog/_next/static/xKGKkOYAc8R8vOdgxDDZf/_middlewareManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.5">.UrsbL{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;padding:10px 30px;-webkit-text-decoration:none;text-decoration:none;color:black;-webkit-tap-highlight-color:transparent;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}/*!sc*/
.UrsbL:focus{outline:none;}/*!sc*/
data-styled.g2[id="StyledLink__AnchorTag-sc-1001dlb-1"]{content:"UrsbL,"}/*!sc*/
.dYSPYo{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;width:100%;}/*!sc*/
data-styled.g3[id="Header__Container-sc-13fiemu-0"]{content:"dYSPYo,"}/*!sc*/
.hGyWUd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;width:220px;}/*!sc*/
data-styled.g4[id="Header__Left-sc-13fiemu-1"]{content:"hGyWUd,"}/*!sc*/
.edgYtU{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;width:calc(100% - 220px);overflow:none;}/*!sc*/
data-styled.g5[id="Header__Middle-sc-13fiemu-2"]{content:"edgYtU,"}/*!sc*/
.eJxZWF{position:absolute;top:0;right:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:60px;height:100%;background-color:white;}/*!sc*/
data-styled.g7[id="Header__Right-sc-13fiemu-4"]{content:"eJxZWF,"}/*!sc*/
.fcVijG{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:10px;width:40px;height:40px;cursor:pointer;border:1px solid #d3d3d3;border-radius:50%;-webkit-tap-highlight-color:transparent;font-size:1.2rem;}/*!sc*/
@media (hover:hover){.fcVijG:hover{background:#d3d3d3;}}/*!sc*/
data-styled.g8[id="Header__MenuButtonItem-sc-13fiemu-5"]{content:"fcVijG,"}/*!sc*/
.ekaHDe{margin-left:6px;height:40px;cursor:pointer;text-align:center;-webkit-tap-highlight-color:transparent;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}/*!sc*/
data-styled.g9[id="Header__LogoItem-sc-13fiemu-6"]{content:"ekaHDe,"}/*!sc*/
.eqLAjq{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:4px;height:30px;cursor:pointer;border-radius:12px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}/*!sc*/
@media (hover:hover){.eqLAjq:hover{background:#d3d3d3;}}/*!sc*/
data-styled.g12[id="Header__HeaderItem-sc-13fiemu-9"]{content:"eqLAjq,"}/*!sc*/
.hhsZYw{position:absolute;z-index:1000;top:0;left:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;height:100%;width:0px;-webkit-transition:width 0.2s ease-out;transition:width 0.2s ease-out;overflow-y:overlay;}/*!sc*/
.hhsZYw::-webkit-scrollbar{width:4px;}/*!sc*/
.hhsZYw::-webkit-scrollbar-track{background:#d3d3d3;}/*!sc*/
.hhsZYw::-webkit-scrollbar-thumb{background:grey;}/*!sc*/
.hhsZYw::-webkit-scrollbar-thumb:hover{background:black;}/*!sc*/
data-styled.g14[id="SideBar__Container-sc-3wui5d-0"]{content:"hhsZYw,"}/*!sc*/
*{box-sizing:border-box;}/*!sc*/
html,body{margin:0;padding:0;font-size:16px;overflow:hidden;}/*!sc*/
data-styled.g22[id="sc-global-jEDTxm1"]{content:"sc-global-jEDTxm1,"}/*!sc*/
.krcVEB{position:absolute;top:0;left:0;right:0;bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;height:100%;overflow:hidden;}/*!sc*/
data-styled.g23[id="MainApp__GlobalContainer-sc-1rpcipa-0"]{content:"krcVEB,"}/*!sc*/
.ewsZwM{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;height:100%;}/*!sc*/
data-styled.g24[id="MainApp__Container-sc-1rpcipa-1"]{content:"ewsZwM,"}/*!sc*/
.fbkGGC{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;height:50px;border-bottom:1px solid #d3d3d3;}/*!sc*/
data-styled.g25[id="MainApp__HeaderContainer-sc-1rpcipa-2"]{content:"fbkGGC,"}/*!sc*/
.dfELKT{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;height:calc(100% - 50px);}/*!sc*/
data-styled.g26[id="MainApp__ContentContainer-sc-1rpcipa-3"]{content:"dfELKT,"}/*!sc*/
.cpybIA{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding:0 20px;width:100%;max-width:800px;}/*!sc*/
data-styled.g36[id="MarkDownComponent__MarkDownContainer-sc-k3onaj-0"]{content:"cpybIA,"}/*!sc*/
.gjyNUS{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;height:100%;}/*!sc*/
data-styled.g37[id="path__Container-sc-ky1y75-0"]{content:"gjyNUS,"}/*!sc*/
.fQsNxc{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;width:100%;height:24px;font-size:12px;padding:2px;padding-right:20px;}/*!sc*/
data-styled.g38[id="path__TopContainer-sc-ky1y75-1"]{content:"fQsNxc,"}/*!sc*/
.grtMOo{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;overflow-y:overlay;width:100%;height:calc(100% - 24px);overflow-y:overlay;}/*!sc*/
.grtMOo::-webkit-scrollbar{width:4px;}/*!sc*/
.grtMOo::-webkit-scrollbar-track{background:#d3d3d3;}/*!sc*/
.grtMOo::-webkit-scrollbar-thumb{background:grey;}/*!sc*/
.grtMOo::-webkit-scrollbar-thumb:hover{background:black;}/*!sc*/
data-styled.g39[id="path__BottomContainer-sc-ky1y75-2"]{content:"grtMOo,"}/*!sc*/
</style></head></html>