<!DOCTYPE html><html><head><meta name="viewport" content="width=device-width"/><meta charSet="utf-8"/><meta name="google-site-verification" content="jYPfVliBMi2ENInqMBmjlQy7QaQYlNJFcz3CKbpQxiE"/><meta name="next-head-count" content="3"/><body><div id="__next" data-reactroot=""><div class="MainApp__GlobalContainer-sc-1rpcipa-0 krcVEB"><div class="MainApp__Container-sc-1rpcipa-1 ewsZwM"><div class="MainApp__HeaderContainer-sc-1rpcipa-2 fbkGGC"><div class="Header__Container-sc-13fiemu-0 dYSPYo"><div class="Header__Left-sc-13fiemu-1 hGyWUd"><div class="Header__MenuButtonItem-sc-13fiemu-5 fcVijG"><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 1024 1024" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M904 160H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0 624H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8zm0-312H120c-4.4 0-8 3.6-8 8v64c0 4.4 3.6 8 8 8h784c4.4 0 8-3.6 8-8v-64c0-4.4-3.6-8-8-8z"></path></svg></div><div class="Header__LogoItem-sc-13fiemu-6 ekaHDe"><span style="box-sizing:border-box;display:inline-block;overflow:hidden;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;position:relative;max-width:100%"><span style="box-sizing:border-box;display:block;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0;max-width:100%"><img style="display:block;max-width:100%;width:initial;height:initial;background:none;opacity:1;border:0;margin:0;padding:0" alt="" aria-hidden="true" src="data:image/svg+xml,%3csvg%20xmlns=%27http://www.w3.org/2000/svg%27%20version=%271.1%27%20width=%27100%27%20height=%2740%27/%3e"/></span><img alt="logo" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%"/><noscript><img alt="logo" srcSet="/blog/barcode.png?imwidth=128 1x, /blog/barcode.png?imwidth=256 2x" src="/blog/barcode.png?imwidth=256" decoding="async" data-nimg="intrinsic" style="position:absolute;top:0;left:0;bottom:0;right:0;box-sizing:border-box;padding:0;border:none;margin:auto;display:block;width:0;height:0;min-width:100%;max-width:100%;min-height:100%;max-height:100%" loading="lazy"/></noscript></span></div></div><div class="Header__Middle-sc-13fiemu-2 edgYtU"><div class="Header__HeaderItem-sc-13fiemu-9 eqLAjq"><a href="/blog/00.research" class="StyledLink__AnchorTag-sc-1001dlb-1 UrsbL">연구</a></div><div class="Header__HeaderItem-sc-13fiemu-9 eqLAjq"><a href="/blog/01.development" class="StyledLink__AnchorTag-sc-1001dlb-1 UrsbL">개발</a></div><div class="Header__HeaderItem-sc-13fiemu-9 eqLAjq"><a href="/blog/02.study" class="StyledLink__AnchorTag-sc-1001dlb-1 UrsbL">아무거나 정리</a></div><div class="Header__HeaderItem-sc-13fiemu-9 eqLAjq"><a href="/blog/03.project" class="StyledLink__AnchorTag-sc-1001dlb-1 UrsbL">토이 프로젝트</a></div></div><div class="Header__Right-sc-13fiemu-4 eJxZWF"></div></div></div><div class="MainApp__ContentContainer-sc-1rpcipa-3 dfELKT"><div class="SideBar__Container-sc-3wui5d-0 hhsZYw"></div><div class="path__Container-sc-ky1y75-0 gjyNUS"><div class="path__TopContainer-sc-ky1y75-1 fQsNxc"><div>오늘 방문자: <!-- -->0<!-- --> (총 방문자: <!-- -->55<!-- -->)</div></div><div class="path__BottomContainer-sc-ky1y75-2 grtMOo"><div class="MarkDownComponent__MarkDownContainer-sc-k3onaj-0 cpybIA"><div class="markdown"><h1>Coin Tossing (동전 던지기)</h1>
<blockquote>
<p>동전을 던졌을 때, 앞면이 나올 확률을 데이터에 기반하여 추정해보자</p>
</blockquote>
<img width="180" src="/blog//assets/research/bayesian-inference/coin-tossing/coin-tossing.jpg"/>
<p>동전을 던졌을 때, 앞면이 나올 확률은 얼마일까? 우리는 경험적으로 앞면이 나올 확률은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mstyle displaystyle="true" scriptlevel="0"><mfrac><mn>1</mn><mn>2</mn></mfrac></mstyle></mrow><annotation encoding="application/x-tex">\cfrac 1 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.276em;vertical-align:-0.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span></span></span></span></span></span></span>이라고 알고 있다.</p>
<p>여기서 경험적으로 알고 있다라는 것은 데이터에 기반한 것이다라고 생각할 수 있고, 이것은 분명 많은 관측치(Observation)를 통해서 추정해 낸 것일 것이다. 이러한 활동이 사실 기계 학습(Machine Learning)에서 하는 것과 정확하게 일치한다고 할 수 있다.</p>
<p>다시 본론으로 돌아와서, 다음의 상황을 가정해 보자.</p>
<p>동전 한 개가 주어져 있고, 동전을 던졌을 때, 동전의 앞면이 나올 확률 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>H</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(H)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mclose">)</span></span></span></span></span>이 얼마일 지 추정해 보고 싶다. 이를 위해서는 먼저 주어져 있는 동전을 여러번 던져보는 시뮬레이션?이 필요하다.</p>
<p>예를 들어 동전을 3번 던져 보고 다음과 같은 결과를 얻었다고 하자. 이때 각 시행은 i.i.d. (independent and identically distributed)라고 가정한다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>H</mi><mo separator="true">,</mo><mi>H</mi><mo separator="true">,</mo><mi>T</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
H, H, T
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5em;vertical-align:-0.5em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1em"><span style="top:-3.16em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<ul>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi></mrow><annotation encoding="application/x-tex">H</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.08125em">H</span></span></span></span></span>: 동전 앞면</li>
<li><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span></span></span>: 동전 뒷면</li>
</ul>
<p>위의 관측치들을 토대로, 일반적으로는 동전 앞면이 나올 확률은 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>H</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle displaystyle="true" scriptlevel="0"><mfrac><mn>2</mn><mn>3</mn></mfrac></mstyle></mrow><annotation encoding="application/x-tex">P(H) = \cfrac 2 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:2.276em;vertical-align:-0.686em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span></span></span></span></span></span></span> 라고 판단할 수 있다. (물론 동전 던지기 시행 횟수가 3번은 매우 적은 숫자이기는 하다.)</p>
<blockquote>
<p>위와 같은 해석이 앞으로 설명할 Maximum Likelihood Estimation 방식이라고 할 수 있다.</p>
</blockquote>
<p>이것을 좀 더 formal하게 설명 해 본다면,</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>H</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mi>μ</mi></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>T</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mn>1</mn><mo>−</mo><mi>μ</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
P(H) &amp;= \mu \\ P(T) &amp;= 1-\mu
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3em;vertical-align:-1.25em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em"><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mclose">)</span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.75em"><span style="top:-3.91em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">μ</span></span></span><span style="top:-2.41em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.25em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p>동전 앞/뒤면이 나올 확률을 각 각 위와 같이 표현할 수 있고, 이때 이 확률 분포는 베르누이 분포(Bernoulli Distribution)를 따른다고 볼 수 있다. 즉, 동전을 던졌을 때 나오는 관측값(ex: <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>H</mi><mo separator="true">,</mo><mi>H</mi><mo separator="true">,</mo><mi>T</mi></mrow><annotation encoding="application/x-tex">H, H, T</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8778em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span></span></span>) 들은 베르누이 분포로 부터의 샘플이라고 생각할 수 있다.</p>
<p>따라서, 동전 던지기의 반복된 시행으로부터 얻은 데이터 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi><mo>=</mo><mo stretchy="false">{</mo><msub><mi>x</mi><mn>1</mn></msub><mo separator="true">,</mo><msub><mi>x</mi><mn>2</mn></msub><mo separator="true">,</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><msub><mi>x</mi><mi>N</mi></msub><mo stretchy="false">}</mo></mrow><annotation encoding="application/x-tex">D = \lbrace x_1, x_2, ... x_N \rbrace</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mopen">{</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3011em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord">...</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">}</span></span></span></span></span>, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x_i=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.5806em;vertical-align:-0.15em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3117em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">i</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span>(앞면) 또는 0(뒷면) 라고 할 때,</p>
<p>데이터의 Likelihood는 다음과 같이 계산된다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mi mathvariant="normal">∣</mi><mi>μ</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∏</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>p</mi><mo stretchy="false">(</mo><msub><mi>x</mi><mi>n</mi></msub><mi mathvariant="normal">∣</mi><mi>μ</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∏</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mi>μ</mi><msub><mi>x</mi><mi>n</mi></msub></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mo>−</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></msup></mstyle></mstyle></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
P(D|\mu)
=
\displaystyle\prod_{n=1}^{N} p(x_n|\mu)
=
\displaystyle\prod_{n=1}^{N} \mu^{x_n}(1-\mu)^{1-x_n}
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.3954em;vertical-align:-1.4477em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9477em"><span style="top:-3.9477em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord">∣</span><span class="mord mathnormal">μ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8829em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">p</span><span class="mopen">(</span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord">∣</span><span class="mord mathnormal">μ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8829em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4477em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<figcaption align="center">
  <b>식 1: Likelihood</b>
</figcaption>
<p>위 식을 좀 더 고민해 볼 필요가 있는게, 지금 내가 가지고 있는 &quot;동전&quot;이 얼마나 앞면을 잘 나오게 하는 동전인가에 대한 모델 관점에서 바라본다면,
&quot;동전 모델&quot;을 설명하는 중요한 파라미터는 베르누이 분포의 파라미터인 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span>라고 할 수 있다.</p>
<p>즉, 기계학습의 관점에서는 주어진 데이터(<span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span></span>)를 통해서 모델의 파라미터인 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span>를 찾는 것이 목표라고 할 수 있다.</p>
<p>이때, 모델 파라미터를 찾는 접근 방식을 다음의 세가지로 구분 할 수 있는데,</p>
<ol>
<li>Maximum Likelihood Estimation (MLE)</li>
<li>Maximum a Posteriori (MAP)</li>
<li>Bayesian Inference</li>
</ol>
<p>하나씩 어떤 특성이 있는지 알아보도록 하겠다.</p>
<h2>Maximum Likelihood Estimation (MLE)</h2>
<p>지금 설명하는 MLE 방식은, 대부분의 전통적인 기계학습 모델 뿐만 아니라, 현재 많이 쓰이고 있는 뉴럴 네트워크 모델의 weight 혹은 parameter 값을 구하는데 사용되는 가장 일반적인 방법이다.</p>
<p>위 동전 던지기 상황에서 Maximum Likelihood Estimation 방식으로 파라미터를 추정해 본다면, 말 그대로 위 식 1 likehood를 최대로 하는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span>를 찾는 문제가 된다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>μ</mi><mrow><mi>M</mi><mi>L</mi><mi>E</mi></mrow></msub><mo>=</mo><munder><mrow><mi mathvariant="normal">arg max</mi><mo>⁡</mo></mrow><mi>μ</mi></munder><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mi mathvariant="normal">∣</mi><mi>μ</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\mu_{MLE} = \argmax_{\mu} P(D|\mu)
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.1705em;vertical-align:-0.8353em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3353em"><span style="top:-3.4953em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.05764em">E</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em"><span style="top:-2.2056em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">μ</span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em">arg</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathrm">max</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0305em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord">∣</span><span class="mord mathnormal">μ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8353em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p>이는 식 1에 로그를 취하고,</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>ln</mi><mo>⁡</mo><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mi mathvariant="normal">∣</mi><mi>μ</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><mi>ln</mi><mo>⁡</mo><mi>μ</mi><mo>+</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mi>ln</mi><mo>⁡</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>μ</mi><mo stretchy="false">)</mo></mstyle></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\ln P(D|\mu)
=
\displaystyle\sum_{n=1}^{N} \ln \mu + (1-x_n) \ln(1-\mu)
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:3.3954em;vertical-align:-1.4477em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.9477em"><span style="top:-3.9477em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mop">ln</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord">∣</span><span class="mord mathnormal">μ</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8829em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">ln</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">ln</span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">μ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.4477em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span>에 대한 미분값이 0인 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span>값(극대값)을 찾는 방식을 통해 다음과 같이 계산 할 수 있다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mfrac><mi>d</mi><mrow><mi>d</mi><mi>μ</mi></mrow></mfrac><mi>ln</mi><mo>⁡</mo><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mi mathvariant="normal">∣</mi><mi>μ</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∑</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msub><mi>x</mi><mi>n</mi></msub><mfrac><mn>1</mn><mi>μ</mi></mfrac><mo>−</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msub><mi>x</mi><mi>n</mi></msub><mo stretchy="false">)</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>−</mo><mi>μ</mi></mrow></mfrac></mstyle></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mn>1</mn><mi>μ</mi></mfrac><mi>h</mi><mo>−</mo><mfrac><mn>1</mn><mrow><mn>1</mn><mo>−</mo><mi>μ</mi></mrow></mfrac><mi>t</mi><mo>=</mo><mn>0</mn></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\cfrac d {d\mu} \ln P(D|\mu)
&amp;=
\displaystyle\sum_{n=1}^{N} x_n \cfrac 1 \mu - (1-x_n) \cfrac 1 {1-\mu}

\\ &amp;=
\cfrac 1 \mu h - \cfrac 1 {1-\mu} t = 0

\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:6.1659em;vertical-align:-2.8329em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.3329em"><span style="top:-5.3329em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">d</span><span class="mord mathnormal">μ</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">d</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mop">ln</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord">∣</span><span class="mord mathnormal">μ</span><span class="mclose">)</span></span></span><span style="top:-2.1758em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.8329em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.3329em"><span style="top:-5.3329em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8829em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">μ</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1514em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mclose">)</span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">μ</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span></span></span></span></span><span style="top:-2.1758em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">μ</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span></span></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">μ</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span></span></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord">0</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.8329em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p>따라서, MLE 방식으로 구한 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span> 값은 아래와 같다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>μ</mi><mrow><mi>M</mi><mi>L</mi><mi>E</mi></mrow></msub><mo>=</mo><mfrac><mi>h</mi><mrow><mi>t</mi><mo>+</mo><mi>h</mi></mrow></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\mu_{MLE} = \cfrac h {t+h}
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.6593em;vertical-align:-1.0797em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5797em"><span style="top:-3.5797em"><span class="pstrut" style="height:3.59em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span><span class="mord mathnormal mtight">L</span><span class="mord mathnormal mtight" style="margin-right:0.05764em">E</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">h</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.7693em"><span></span></span></span></span></span><span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0797em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p>결과적으로 MLE 방식으로 앞서 동전 던지기의 상황에 대한 파라미터 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span>를 추정한다면, 앞면이 나온 횟수 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>h</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">h=2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">2</span></span></span></span></span>, 뒷면이 나온 횟수 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">t=1</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span></span><span class="base"><span class="strut" style="height:0.6444em"></span><span class="mord">1</span></span></span></span></span> 이기 때문에</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>H</mi><mo stretchy="false">)</mo><mo>=</mo><mi>μ</mi><mo>=</mo><mfrac><mn>2</mn><mn>3</mn></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
P(H) = \mu = \cfrac 2 3
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.576em;vertical-align:-1.038em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.538em"><span style="top:-3.538em"><span class="pstrut" style="height:3.59em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.08125em">H</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal">μ</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">3</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord">2</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.038em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p>이 되고, 이것은 맨 처음 가장 상식적으로? 동전의 앞면이 나올 확률을 예측한 것과 동일한 것을 알 수 있다.</p>
<h2>Maximum a Posteriori (MAP)</h2>
<p>위 MLE 방식에는 맹점이 있다. 만약 동전을 여러번 던졌는데 그 결과가 아래와 같다면 어떨까?</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>T</mi><mo separator="true">,</mo><mi>T</mi><mo separator="true">,</mo><mi>T</mi></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
T, T, T
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.5em;vertical-align:-0.5em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1em"><span style="top:-3.16em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span><span class="mpunct">,</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">T</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.5em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p>이런 상황이 발생한다면, MLE 방식으로 동전 앞면이 나올 확률, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span>를 추정했을때는 0 이 될 것이다.
이는 주어진 데이터의 불완정성으로 인해 모델 학습 과정에서 overfitting을 발생 시킬 소지가 있다는 것이다.</p>
<p>이후 설명 할 MAP, 그리고 Bayesian 방식의 모델 파라미터 추정 방식은 이러한 문제를 방지하면서 좀 더 robust한 모델을 학습 하기 위한 철학이라고 생각하면 된다.</p>
<blockquote>
<p>사실 데이터가 충분히 많을 경우 위와 같은 문제는 거의 없다고 봐도 되지만, 현실 문제에 있어서 모든 현상을 완벽하게 설명하는 모델을 만들기 어렵고, 데이터 관점에서도 학습을 위해 구축되어 있는 데이터는 실제 우주에 존재하는 모든 관측 가능한 샘플 집합의 극히 일부분임을 감안할 때, 개인적으로는 가능하기만 하다면 Bayesian 방식의 접근법이 합리적이라고 생각한다.</p>
</blockquote>
<p>MAP 방식은 MLE 방식에 비해 조금 더 Bayesian스러운 방식이다.</p>
<p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span>를 학습하기 위해 다음과 같은 식을 생각해보자.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>P</mi><mi>o</mi><mi>s</mi><mi>t</mi><mi>e</mi><mi>r</mi><mi>i</mi><mi>o</mi><mi>r</mi></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi>L</mi><mi>i</mi><mi>k</mi><mi>e</mi><mi>l</mi><mi>i</mi><mi>h</mi><mi>o</mi><mi>o</mi><mi>d</mi><mo>×</mo><mi>P</mi><mi>r</mi><mi>i</mi><mi>o</mi><mi>r</mi></mrow><mrow><mi>E</mi><mi>v</mi><mi>i</mi><mi>d</mi><mi>e</mi><mi>n</mi><mi>c</mi><mi>e</mi></mrow></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mi mathvariant="normal">∣</mi><mi>μ</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mo stretchy="false">)</mo></mrow><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mo stretchy="false">)</mo></mrow></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>∝</mo><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mi mathvariant="normal">∣</mi><mi>μ</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
Posterior &amp;= \cfrac {Likelihood \times Prior} {Evidence}

\\

P(\mu|D)
&amp;=
\cfrac {P(D|\mu)P(\mu)} {P(D)}

\\ &amp;\propto
P(D|\mu)P(\mu)

\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:6.902em;vertical-align:-3.201em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.701em"><span style="top:-5.701em"><span class="pstrut" style="height:3.59em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mord mathnormal">os</span><span class="mord mathnormal">t</span><span class="mord mathnormal" style="margin-right:0.02778em">er</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.02778em">or</span></span></span><span style="top:-3.125em"><span class="pstrut" style="height:3.59em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span><span style="top:-1.049em"><span class="pstrut" style="height:3.59em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.201em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.701em"><span style="top:-5.701em"><span class="pstrut" style="height:3.59em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.05764em">E</span><span class="mord mathnormal" style="margin-right:0.03588em">v</span><span class="mord mathnormal">i</span><span class="mord mathnormal">d</span><span class="mord mathnormal">e</span><span class="mord mathnormal">n</span><span class="mord mathnormal">ce</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">L</span><span class="mord mathnormal" style="margin-right:0.03148em">ik</span><span class="mord mathnormal">e</span><span class="mord mathnormal" style="margin-right:0.01968em">l</span><span class="mord mathnormal">ih</span><span class="mord mathnormal">oo</span><span class="mord mathnormal">d</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mord mathnormal" style="margin-right:0.02778em">r</span><span class="mord mathnormal">i</span><span class="mord mathnormal" style="margin-right:0.02778em">or</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.686em"><span></span></span></span></span></span><span></span></span></span></span><span style="top:-3.125em"><span class="pstrut" style="height:3.59em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord">∣</span><span class="mord mathnormal">μ</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.936em"><span></span></span></span></span></span><span></span></span></span></span><span style="top:-1.049em"><span class="pstrut" style="height:3.59em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord">∣</span><span class="mord mathnormal">μ</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.201em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<figcaption align="center">
  <b>식 2: Bayes&#x27; Rule</b>
</figcaption>
<p>결론을 먼저 얘기하자면,</p>
<p>MAP는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\mu|D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span></span>, 즉 데이터 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>D</mi></mrow><annotation encoding="application/x-tex">D</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6833em"></span><span class="mord mathnormal" style="margin-right:0.02778em">D</span></span></span></span></span>가 주어졌을 때, 가장 그럴듯한 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span>를 찾는 것을 목표로 하는 것이고, MAP에서는 point estimates, 다시 말하면 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\mu|D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span></span>의 극대값을 찾는 것을 말한다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>μ</mi><mrow><mi>M</mi><mi>A</mi><mi>P</mi></mrow></msub><mo>=</mo><munder><mrow><mi mathvariant="normal">arg max</mi><mo>⁡</mo></mrow><mi>μ</mi></munder><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\mu_{MAP} = \argmax_{\mu} P(\mu|D)
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.1705em;vertical-align:-0.8353em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.3353em"><span style="top:-3.4953em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span><span class="mord mathnormal mtight">A</span><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.4306em"><span style="top:-2.2056em;margin-left:0em"><span class="pstrut" style="height:3em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">μ</span></span></span></span><span style="top:-3em"><span class="pstrut" style="height:3em"></span><span><span class="mop"><span class="mord mathrm" style="margin-right:0.01389em">arg</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathrm">max</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0305em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8353em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p>이때 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\mu|D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span></span>를 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span>에 대한 사후 확률 분포(Posterior)라 하고, 이것은 식 2에서 처럼 베이즈 정리에 따라 가능도(Likelihood)와 사전 확률 분포(Prior)의 곱으로 표현할 수 있다.</p>
<p>동전 던지기 상황에서 위 식을 적용한다면,</p>
<p><span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mi mathvariant="normal">∣</mi><mi>μ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(D|\mu)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord">∣</span><span class="mord mathnormal">μ</span><span class="mclose">)</span></span></span></span></span>는 위 식 1 Likehood를, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\mu)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mclose">)</span></span></span></span></span>는 베타 분포(Beta Distribution)를 사용하여 다음과 같이 정리할 수 있다.</p>
<blockquote>
<p>베르누이 분포의 conjugate prior인 베타분포를 이용하면 계산이 간편해 진다.</p>
</blockquote>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>∝</mo><mi>P</mi><mo stretchy="false">(</mo><mi>D</mi><mi mathvariant="normal">∣</mi><mi>μ</mi><mo stretchy="false">)</mo><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>∝</mo><mstyle scriptlevel="0" displaystyle="true"><munderover><mo>∏</mo><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><mi>N</mi></munderover><msup><mi>μ</mi><msub><mi>x</mi><mi>n</mi></msub></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mrow><mn>1</mn><mo>−</mo><msub><mi>x</mi><mi>n</mi></msub></mrow></msup><mo>⋅</mo><msup><mi>μ</mi><mrow><mi>α</mi><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mrow><mi>β</mi><mo>−</mo><mn>1</mn></mrow></msup></mstyle></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>∝</mo><msup><mi>μ</mi><mi>h</mi></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mi>t</mi></msup><mo>⋅</mo><msup><mi>μ</mi><mrow><mi>α</mi><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mrow><mi>β</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>∝</mo><msup><mi>μ</mi><mrow><mi>h</mi><mo>+</mo><mi>α</mi><mo>−</mo><mn>1</mn></mrow></msup><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>μ</mi><msup><mo stretchy="false">)</mo><mrow><mi>t</mi><mo>+</mo><mi>β</mi><mo>−</mo><mn>1</mn></mrow></msup></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
P(\mu|D)
&amp;\propto
P(D|\mu)P(\mu)
\\ &amp;\propto
\displaystyle\prod_{n=1}^{N} \mu^{x_n}(1-\mu)^{1-x_n} \cdot \mu^{\alpha-1}(1-\mu)^{\beta-1}
\\ &amp;\propto
\mu^h(1-\mu)^{t} \cdot \mu^{\alpha-1}(1-\mu)^{\beta-1}
\\ &amp;\propto
\mu^{h+\alpha-1}(1-\mu)^{t+\beta-1}
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:8.0137em;vertical-align:-3.7568em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.2568em"><span style="top:-7.2452em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span><span style="top:-4.7568em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"></span></span><span style="top:-2.2906em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"></span></span><span style="top:-0.7315em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.7568em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:4.2568em"><span style="top:-7.2452em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mord">∣</span><span class="mord mathnormal">μ</span><span class="mclose">)</span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mclose">)</span></span></span><span style="top:-4.7568em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8829em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span><span class="mrel mtight">=</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∏</span></span></span><span style="top:-4.3em;margin-left:0em"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">N</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.2671em"><span></span></span></span></span></span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.7144em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mbin mtight">−</span><span class="mord mtight"><span class="mord mathnormal mtight">x</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.1645em"><span style="top:-2.357em;margin-left:0em;margin-right:0.0714em"><span class="pstrut" style="height:2.5em"></span><span class="sizing reset-size3 size1 mtight"><span class="mord mathnormal mtight">n</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.143em"><span></span></span></span></span></span></span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em">α</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em">β</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span><span style="top:-2.2906em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mathnormal mtight">h</span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8436em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span></span></span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">⋅</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8641em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.0037em">α</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.05278em">β</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span><span style="top:-0.7315em"><span class="pstrut" style="height:3.8283em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">∝</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">h</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.0037em">α</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span><span class="mopen">(</span><span class="mord">1</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">μ</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:0.8991em"><span style="top:-3.113em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">t</span><span class="mbin mtight">+</span><span class="mord mathnormal mtight" style="margin-right:0.05278em">β</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span></span></span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:3.7568em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<figcaption align="center">
  <b>식 3: 동전 앞면이 나올 확률에 대한 사후 확률 분포</b>
</figcaption>
<p>마찬가지로, \mu의 극대값을 구하기위해 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\mu|D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span></span> 식의 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>μ</mi></mrow><annotation encoding="application/x-tex">\mu</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.625em;vertical-align:-0.1944em"></span><span class="mord mathnormal">μ</span></span></span></span></span>에 대한 미분값을 0으로 하여 계산하게 되면, 아래와 같은 결과를 얻을 수 있다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><msub><mi>μ</mi><mrow><mi>M</mi><mi>A</mi><mi>P</mi></mrow></msub><mo>=</mo><mfrac><mrow><mi>h</mi><mo>+</mo><mi>α</mi><mo>−</mo><mn>1</mn></mrow><mrow><mi>h</mi><mo>+</mo><mi>t</mi><mo>+</mo><mi>α</mi><mo>+</mo><mi>β</mi><mo>−</mo><mn>2</mn></mrow></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\mu_{MAP} = \cfrac {h+\alpha-1} {h+t+\alpha+\beta-2}
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.7704em;vertical-align:-1.1352em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.6352em"><span style="top:-3.6352em"><span class="pstrut" style="height:3.59em"></span><span class="mord"><span class="mord"><span class="mord mathnormal">μ</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:0.3283em"><span style="top:-2.55em;margin-left:0em;margin-right:0.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:0.10903em">M</span><span class="mord mathnormal mtight">A</span><span class="mord mathnormal mtight" style="margin-right:0.13889em">P</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">t</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord">2</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord">1</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.1352em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p>이때, 동전 시행 횟수가 무한히 많아진다면, 위 식에서 상대적으로 작은 값인 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi></mrow><annotation encoding="application/x-tex">\alpha</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.4306em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span></span></span></span></span>와 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi></mrow><annotation encoding="application/x-tex">\beta</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span></span></span></span></span>의 영향이 거의 없어지기 때문에, 위 값은 위 MLE 방식의 파라미터 추정값과 동일하게 된다고 볼 수 있다. MAP에서 사전 확률 분포를 Uniform Distribution으로 설정하면 이것은 MLE와 같은 결과를 얻을 수 있다.</p>
<h2>Bayesian Inference</h2>
<p>위 MAP 방식은 어느정도 Bayesian 방식의 철학을 담고 있다고 하였다. 하지만 MAP로 추정한 파라미터 값 역시 point estimates이기 때문에 한계를 가진다.</p>
<p>진정한 Bayesian 관점으로 파라미터를 추정하기 위해서는 더 많은 정보를 담고 있는 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\mu|D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span></span> 분포를 이용하여 사후 확률 분포의 평균(Posterior mean)을 구하는 것이 필요하다. 즉, 모든 가능한 파라미터 셋팅에 대해 평균을 취하는 것이 가장 이상적인 선택이라는 뜻이다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right" columnspacing=""><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="double-struck">E</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo><mo>=</mo><mstyle scriptlevel="0" displaystyle="true"><mo>∫</mo><mi>μ</mi><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo><mi>d</mi><mi>μ</mi></mstyle></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\mathbb{E}(\mu|D) = \displaystyle\int \mu P(\mu|D) d\mu
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:2.5223em;vertical-align:-1.0111em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.5111em"><span style="top:-3.5111em"><span class="pstrut" style="height:3.36em"></span><span class="mord"><span class="mord mathbb">E</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mop op-symbol large-op" style="margin-right:0.44445em;position:relative;top:-0.0011em">∫</span><span class="mspace" style="margin-right:0.1667em"></span><span class="mord mathnormal">μ</span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span><span class="mord mathnormal">d</span><span class="mord mathnormal">μ</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.0111em"><span></span></span></span></span></span></span></span></span></span></span></span></div>
<p>일반적으로 위 적분은 계산하기가 어려운 경우가 많아 특별한 inference 방식을 사용해야한다.</p>
<blockquote>
<p>Gibbs Sampling 혹은 Variational Inference가 대표적이다.</p>
</blockquote>
<p>하지만, 위 식의 경우에는 굉장히 간단한 방법으로 계산을 할 수가 있는데, 앞서 설명 했듯이 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\mu|D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span></span>는 Likelihood가 베르누이 분포, Prior가 베타 분포로 형성된 Posterior 이다.</p>
<p>베르누이 분포의 conjugate prior인 베타분포를 Prior로 둔 이유가 여기에 있는데, Likelihood와 Prior의 곱으로 표현되는 Posterior 역시 베타 분포로 그 형태가 동일하게 되기 때문에, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>P</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">P(\mu|D)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-0.25em"></span><span class="mord mathnormal" style="margin-right:0.13889em">P</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span></span></span>는 파라미터를 <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>α</mi><mo>+</mo><mi>h</mi></mrow><annotation encoding="application/x-tex">\alpha+h</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.6667em;vertical-align:-0.0833em"></span><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6944em"></span><span class="mord mathnormal">h</span></span></span></span></span>, <span class="math math-inline"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>β</mi><mo>+</mo><mi>t</mi></mrow><annotation encoding="application/x-tex">\beta+t</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:0.8889em;vertical-align:-0.1944em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span></span><span class="base"><span class="strut" style="height:0.6151em"></span><span class="mord mathnormal">t</span></span></span></span></span>로 가지는 베타 분포이고, 이 베타분포의 기댓값이 바로 앞서 구하려고 했던 Posterior mean이라고 볼 수 있다.</p>
<div class="math math-display"><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mtable rowspacing="0.25em" columnalign="right left" columnspacing="0em"><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mi mathvariant="double-struck">E</mi><mo stretchy="false">(</mo><mi>μ</mi><mi mathvariant="normal">∣</mi><mi>D</mi><mo stretchy="false">)</mo></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi>α</mi><mo>+</mo><mi>h</mi></mrow><mrow><mi>α</mi><mo>+</mo><mi>β</mi><mo>+</mo><mi>h</mi><mo>+</mo><mi>t</mi></mrow></mfrac></mrow></mstyle></mtd></mtr><mtr><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow></mrow></mstyle></mtd><mtd><mstyle scriptlevel="0" displaystyle="true"><mrow><mrow></mrow><mo>=</mo><mfrac><mrow><mi>α</mi><mo>+</mo><mi>h</mi></mrow><mrow><mi>α</mi><mo>+</mo><mi>β</mi><mo>+</mo><mi>N</mi></mrow></mfrac></mrow></mstyle></mtd></mtr></mtable><annotation encoding="application/x-tex">\begin{aligned}
\mathbb{E}(\mu|D)
&amp;= \cfrac {\alpha+h} {\alpha+\beta+h+t}
\\ &amp;= \cfrac {\alpha+h} {\alpha+\beta+N}
\end{aligned}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:5.5409em;vertical-align:-2.5204em"></span><span class="mord"><span class="mtable"><span class="col-align-r"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.0204em"><span style="top:-5.0204em"><span class="pstrut" style="height:3.59em"></span><span class="mord"><span class="mord mathbb">E</span><span class="mopen">(</span><span class="mord mathnormal">μ</span><span class="mord">∣</span><span class="mord mathnormal" style="margin-right:0.02778em">D</span><span class="mclose">)</span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.59em"></span><span class="mord"></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.5204em"><span></span></span></span></span></span><span class="col-align-l"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:3.0204em"><span style="top:-5.0204em"><span class="pstrut" style="height:3.59em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">h</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">t</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span></span></span></span></span><span style="top:-2.25em"><span class="pstrut" style="height:3.59em"></span><span class="mord"><span class="mord"></span><span class="mspace" style="margin-right:0.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:0.2778em"></span><span class="mord"><span class="mopen nulldelimiter"></span><span class="mfrac"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.59em"><span style="top:-2.314em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.05278em">β</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal" style="margin-right:0.10903em">N</span></span></span><span style="top:-3.23em"><span class="pstrut" style="height:3em"></span><span class="frac-line" style="border-bottom-width:0.04em"></span></span><span style="top:-3.74em"><span class="pstrut" style="height:3em"></span><span class="mord"><span class="mord mathnormal" style="margin-right:0.0037em">α</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:0.2222em"></span><span class="mord mathnormal">h</span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:0.8804em"><span></span></span></span></span></span><span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:2.5204em"><span></span></span></span></span></span></span></span></span></span></span></span></div></div></div></div></div></div></div></div></div><script id="__NEXT_DATA__" type="application/json">{"props":{"pageProps":{"mappings":[{"header":{"label":"연구","path":"00.research","md":"","preview":true,"sub":[{"label":"베이지안 추론","path":"bayesian-inference","md":"","preview":true,"sub":[{"label":"Coin Tossing","path":"coin-tossing","md":"","preview":true,"sub":[],"img":"/assets/research/bayesian-inference/coin-tossing/coin-tossing.jpg","snippet":"동전을 던졌을 때, 앞면이 나올 확률을 데이터에 기반하여 추정해보자","depth":2},{"label":"Curve Fitting","path":"curve-fitting","md":"","preview":true,"sub":[],"img":"/assets/research/bayesian-inference/curve-fitting/curve-fitting.JPG","snippet":"가지 중요한 개념을 설명하기에 앞서, 간단한 회귀(Regression) 문제를 소개해 보도록 하겠다.","depth":2},{"label":"Gibbs Sampling","path":"gibbs-sampling","md":"","preview":true,"sub":[],"img":"/assets/study/inverse-transform-sampling/Inverse_Transform_Sampling_Example.gif","snippet":"Gibbs Sampling을 구현하기위해 사용한 Inverse Transform Sampling 기법을 소개하면서 실질적인 구현 방법을 먼저 소개하고, 이론적인 배경은 나중에 업데이트 할 예정이다.","depth":2},{"label":"Variational Inference","path":"variational-inference","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Inference는 [Bayeisan Inference](/docs/research/bayesian-inference)에서 적용되는 테크닉으로 개인적으로는 상당히 공부하기 어려웠던 것 중 하나여서 시간을 내어 정리해 보려고 한다.","depth":2}],"img":"/barcode.png","snippet":"Inference를 설명하기에 앞서 다음과 같은 순서로 각 개념을 이해하는 것이 중요하다.","depth":1},{"label":"가우시안 혼합 모델","path":"gaussian-mixture-model","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"K-means Clustering","path":"k-means","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"K-means 알고리즘은 Gaussian Mixture Model의 특별한 경우이다. 그리고 EM 알고리즘의 Expectation 단계와 Maximazation 단계를 거쳐 학습하는 과정을 거친다.","depth":1},{"label":"Multi-Armed Bandit","path":"multi-armed-bandit","md":"","preview":true,"sub":[],"img":"/assets/research/multi-armed-bandit/mab.JPG","snippet":"여러대의 슬롯 머신이 있다고 하자. 그리고 일확천금을 위해서 어떤 사람이 슬롯 머신을 여기 저기서 당기고 있다. 이때 이 사람이 수익을 극대화 하는 방법이 있을까?","depth":1},{"label":"PageRank","path":"pagerank","md":"","preview":true,"sub":[],"img":"/assets/research/pagerank/pagerank.png","snippet":"상당히 직관적이고 간단하게 이해할 수 있는 개념이지만 그 이면을 들여다 보면 공부할 만한 사실들이 상당히 많이 있다. 그 중 중요하다고 생각하는 부분들에 대해서 소개하려고 한다.","depth":1},{"label":"추천 시스템","path":"recommendation-system","md":"","preview":true,"sub":[{"label":"컨텐츠 기반 알고리즘","path":"contents","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Matrix Factorization","path":"matrix-factorization","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Factorization은 추천 시스템에서 협업 필터링(Collaborative Filtering) 알고리즘에 속한다. 아이디어는 상당히 간단한데 User와 Item을 행과 열로 가진 Matrix 분해햐여 User와 Item을 low dimensional latent space에 사상 시키는 방법이다. 이를 위해 아랴와 같이 크게 두가지 방식으로 User-Item Matrix를 Decomposition 할 수 있다.","depth":2},{"label":"모델 기반 협업 필터링","path":"model","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"neighbor","path":"neighbor","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"Stochastic Process","path":"stochastic-process","md":"","preview":true,"sub":[{"label":"디리클레 프로세스","path":"dirichlet-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"가우시안 프로세스","path":"gaussian-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"혹스 프로세스","path":"hawkes-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"포아송 프로세스","path":"poisson-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"Stochastic Process란, Random Variable(확률 변수) 혹은 function의 collection을 의미한다.","depth":1},{"label":"Singular Value Decomposition","path":"svd","md":"","preview":true,"sub":[],"img":"/assets/research/svd/axis.JPG","snippet":"Singular Value Decomposition (이하 SVD)는 Eigendecomposition의 일반화된 형태이므로 먼저 Eigendecompositon에 대해 정리해 본다.","depth":1},{"label":"Topic Model","path":"topic-modeling","md":"","preview":true,"sub":[{"label":"Adversarial-neural Event Model","path":"aem","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Correlated Topic Model","path":"ctm","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Gaussain LDA","path":"glda","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Hierarchical Dirichlet Process","path":"hdp","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"LDA의 Non-parametric 버전으로 토픽 갯수 K를 지정하지 않아도 되는 더 일반적인 모델","depth":2},{"label":"Latent Dirichlet Allocation","path":"lda","md":"","preview":true,"sub":[],"img":"/assets/research/topic_modeling/lda/dist_desc.JPG","snippet":"LDA는 임의의 문서를 K개의 토픽 분포로 표현하고, 각 토픽은 V개의 단어 분포로 표현하는 모델이다.","depth":2},{"label":"Latent Event Model","path":"lem","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"토픽 모델이 뭔지 정리해보자","depth":1},{"label":"Variational AutoEncoder","path":"variational-autoencoder","md":"","preview":true,"sub":[],"img":"/assets/research/variational-autoencoder/ae-vae.png","snippet":"","depth":1}],"img":"/barcode.png","snippet":"공부했던 것들 중에, 생각할 것들이 많았던 것들을 정리하고 있다.","depth":0},"side_bar":[{"label":"베이지안 추론","path":"bayesian-inference","md":"","preview":true,"sub":[{"label":"Coin Tossing","path":"coin-tossing","md":"","preview":true,"sub":[],"img":"/assets/research/bayesian-inference/coin-tossing/coin-tossing.jpg","snippet":"동전을 던졌을 때, 앞면이 나올 확률을 데이터에 기반하여 추정해보자","depth":2},{"label":"Curve Fitting","path":"curve-fitting","md":"","preview":true,"sub":[],"img":"/assets/research/bayesian-inference/curve-fitting/curve-fitting.JPG","snippet":"가지 중요한 개념을 설명하기에 앞서, 간단한 회귀(Regression) 문제를 소개해 보도록 하겠다.","depth":2},{"label":"Gibbs Sampling","path":"gibbs-sampling","md":"","preview":true,"sub":[],"img":"/assets/study/inverse-transform-sampling/Inverse_Transform_Sampling_Example.gif","snippet":"Gibbs Sampling을 구현하기위해 사용한 Inverse Transform Sampling 기법을 소개하면서 실질적인 구현 방법을 먼저 소개하고, 이론적인 배경은 나중에 업데이트 할 예정이다.","depth":2},{"label":"Variational Inference","path":"variational-inference","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Inference는 [Bayeisan Inference](/docs/research/bayesian-inference)에서 적용되는 테크닉으로 개인적으로는 상당히 공부하기 어려웠던 것 중 하나여서 시간을 내어 정리해 보려고 한다.","depth":2}],"img":"/barcode.png","snippet":"Inference를 설명하기에 앞서 다음과 같은 순서로 각 개념을 이해하는 것이 중요하다.","depth":1},{"label":"가우시안 혼합 모델","path":"gaussian-mixture-model","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"K-means Clustering","path":"k-means","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"K-means 알고리즘은 Gaussian Mixture Model의 특별한 경우이다. 그리고 EM 알고리즘의 Expectation 단계와 Maximazation 단계를 거쳐 학습하는 과정을 거친다.","depth":1},{"label":"Multi-Armed Bandit","path":"multi-armed-bandit","md":"","preview":true,"sub":[],"img":"/assets/research/multi-armed-bandit/mab.JPG","snippet":"여러대의 슬롯 머신이 있다고 하자. 그리고 일확천금을 위해서 어떤 사람이 슬롯 머신을 여기 저기서 당기고 있다. 이때 이 사람이 수익을 극대화 하는 방법이 있을까?","depth":1},{"label":"PageRank","path":"pagerank","md":"","preview":true,"sub":[],"img":"/assets/research/pagerank/pagerank.png","snippet":"상당히 직관적이고 간단하게 이해할 수 있는 개념이지만 그 이면을 들여다 보면 공부할 만한 사실들이 상당히 많이 있다. 그 중 중요하다고 생각하는 부분들에 대해서 소개하려고 한다.","depth":1},{"label":"추천 시스템","path":"recommendation-system","md":"","preview":true,"sub":[{"label":"컨텐츠 기반 알고리즘","path":"contents","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Matrix Factorization","path":"matrix-factorization","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Factorization은 추천 시스템에서 협업 필터링(Collaborative Filtering) 알고리즘에 속한다. 아이디어는 상당히 간단한데 User와 Item을 행과 열로 가진 Matrix 분해햐여 User와 Item을 low dimensional latent space에 사상 시키는 방법이다. 이를 위해 아랴와 같이 크게 두가지 방식으로 User-Item Matrix를 Decomposition 할 수 있다.","depth":2},{"label":"모델 기반 협업 필터링","path":"model","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"neighbor","path":"neighbor","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"Stochastic Process","path":"stochastic-process","md":"","preview":true,"sub":[{"label":"디리클레 프로세스","path":"dirichlet-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"가우시안 프로세스","path":"gaussian-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"혹스 프로세스","path":"hawkes-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"포아송 프로세스","path":"poisson-process","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"Stochastic Process란, Random Variable(확률 변수) 혹은 function의 collection을 의미한다.","depth":1},{"label":"Singular Value Decomposition","path":"svd","md":"","preview":true,"sub":[],"img":"/assets/research/svd/axis.JPG","snippet":"Singular Value Decomposition (이하 SVD)는 Eigendecomposition의 일반화된 형태이므로 먼저 Eigendecompositon에 대해 정리해 본다.","depth":1},{"label":"Topic Model","path":"topic-modeling","md":"","preview":true,"sub":[{"label":"Adversarial-neural Event Model","path":"aem","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Correlated Topic Model","path":"ctm","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Gaussain LDA","path":"glda","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2},{"label":"Hierarchical Dirichlet Process","path":"hdp","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"LDA의 Non-parametric 버전으로 토픽 갯수 K를 지정하지 않아도 되는 더 일반적인 모델","depth":2},{"label":"Latent Dirichlet Allocation","path":"lda","md":"","preview":true,"sub":[],"img":"/assets/research/topic_modeling/lda/dist_desc.JPG","snippet":"LDA는 임의의 문서를 K개의 토픽 분포로 표현하고, 각 토픽은 V개의 단어 분포로 표현하는 모델이다.","depth":2},{"label":"Latent Event Model","path":"lem","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":2}],"img":"/barcode.png","snippet":"토픽 모델이 뭔지 정리해보자","depth":1},{"label":"Variational AutoEncoder","path":"variational-autoencoder","md":"","preview":true,"sub":[],"img":"/assets/research/variational-autoencoder/ae-vae.png","snippet":"","depth":1}]},{"header":{"label":"개발","path":"01.development","md":"","preview":true,"sub":[{"label":"엘라스틱서치","path":"elasticsearch","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"사용했던 것들을 정리해보자.","depth":1},{"label":"개발 환경 구축","path":"env","md":"","preview":true,"sub":[{"label":"code-server","path":"code-server","md":"","preview":true,"sub":[],"img":"/assets/development/env/code-server/code-server.png","snippet":"+ ubuntu 20.04","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"명령어 기록","path":"etc","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"sh","depth":1},{"label":"하둡","path":"hadoop","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"java","path":"java","md":"","preview":true,"sub":[{"label":"자바의 비동기 기술","path":"async","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Future","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"쿠버네티스","path":"k8s","md":"","preview":true,"sub":[{"label":"쿠버네티스 설치","path":"installation","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"집에 놀고 있는 리눅스 머신에 K8S를 설치 해보자","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"메시지 브로커","path":"kafka","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"보내고, 처리하고, 삭제한다.","depth":1},{"label":"코틀린","path":"kotlin","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"루씬","path":"lucene","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"거의 Elasticsearch를 이용해서 프로젝트를 진행하지만, 검색이 필요한 경우 Lucene을 이용해서 개발하는 경우가 많았던 것 같다. JAVA에 Lucence 의존성만 추가하면 뭔가 가볍게 시작할 수 있었기 때문인데 점점 기능이 복잡해 질 수록 Elasticsearch가 얼마나 잘 만들어져 있는 것인가를 느끼고 있다. 그래도 Elasticsearch는 Lucence을 가져다 쓰는거니까 먼저 간단한 것 부터 정리해 볼 계획이다.","depth":1},{"label":"리액트","path":"react","md":"","preview":true,"sub":[{"label":"package.json","path":"package-json","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"dependencies vs devDependencies","depth":2},{"label":"react-snap으로 정적페이지 빌드","path":"react-snap","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Basic usage with create-react-app","depth":2},{"label":"GitHub Pages에 SPA","path":"spa-github-pages","md":"","preview":true,"sub":[],"img":"/assets/development/react/spa-github-pages/github-pages-404.JPG","snippet":"1. 문제 상황","depth":2}],"img":"/assets/development/react/react-app.png","snippet":"React 개발 환경 구축","depth":1},{"label":"스프링 부트","path":"spring-boot","md":"","preview":true,"sub":[{"label":"Spring Boot에서 HTTPS 적용","path":"https","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Certificate 만들기","depth":2},{"label":"Maven에서 Spring Boot 설정","path":"maven-support","md":"","preview":true,"sub":[],"img":"/assets/development/spring-boot/maven-support/multi-module.JPG","snippet":"Maven multi-module 프로젝트에서 Spring Boot Application을 Maven Dependency로 Import하기","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"웹플럭스","path":"webflux","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}],"img":"/barcode.png","snippet":"","depth":0},"side_bar":[{"label":"엘라스틱서치","path":"elasticsearch","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"사용했던 것들을 정리해보자.","depth":1},{"label":"개발 환경 구축","path":"env","md":"","preview":true,"sub":[{"label":"code-server","path":"code-server","md":"","preview":true,"sub":[],"img":"/assets/development/env/code-server/code-server.png","snippet":"+ ubuntu 20.04","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"명령어 기록","path":"etc","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"sh","depth":1},{"label":"하둡","path":"hadoop","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"java","path":"java","md":"","preview":true,"sub":[{"label":"자바의 비동기 기술","path":"async","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Future","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"쿠버네티스","path":"k8s","md":"","preview":true,"sub":[{"label":"쿠버네티스 설치","path":"installation","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"집에 놀고 있는 리눅스 머신에 K8S를 설치 해보자","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"메시지 브로커","path":"kafka","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"보내고, 처리하고, 삭제한다.","depth":1},{"label":"코틀린","path":"kotlin","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"루씬","path":"lucene","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"거의 Elasticsearch를 이용해서 프로젝트를 진행하지만, 검색이 필요한 경우 Lucene을 이용해서 개발하는 경우가 많았던 것 같다. JAVA에 Lucence 의존성만 추가하면 뭔가 가볍게 시작할 수 있었기 때문인데 점점 기능이 복잡해 질 수록 Elasticsearch가 얼마나 잘 만들어져 있는 것인가를 느끼고 있다. 그래도 Elasticsearch는 Lucence을 가져다 쓰는거니까 먼저 간단한 것 부터 정리해 볼 계획이다.","depth":1},{"label":"리액트","path":"react","md":"","preview":true,"sub":[{"label":"package.json","path":"package-json","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"dependencies vs devDependencies","depth":2},{"label":"react-snap으로 정적페이지 빌드","path":"react-snap","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Basic usage with create-react-app","depth":2},{"label":"GitHub Pages에 SPA","path":"spa-github-pages","md":"","preview":true,"sub":[],"img":"/assets/development/react/spa-github-pages/github-pages-404.JPG","snippet":"1. 문제 상황","depth":2}],"img":"/assets/development/react/react-app.png","snippet":"React 개발 환경 구축","depth":1},{"label":"스프링 부트","path":"spring-boot","md":"","preview":true,"sub":[{"label":"Spring Boot에서 HTTPS 적용","path":"https","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"Certificate 만들기","depth":2},{"label":"Maven에서 Spring Boot 설정","path":"maven-support","md":"","preview":true,"sub":[],"img":"/assets/development/spring-boot/maven-support/multi-module.JPG","snippet":"Maven multi-module 프로젝트에서 Spring Boot Application을 Maven Dependency로 Import하기","depth":2}],"img":"/barcode.png","snippet":"","depth":1},{"label":"웹플럭스","path":"webflux","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}]},{"header":{"label":"아무거나 정리","path":"02.study","md":"","preview":true,"sub":[{"label":"Chi-Square Test","path":"chi-square-test","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"검정은 하나 이상의 카테고리에서 관측된 빈도와 기대되는 빈도가 통계적으로 유의하게 다른지 검증하는 기법으로, 카이 제곱 분포에 기초한 통계적 가설 검정 방법이다.","depth":1},{"label":"HTTPS와 공개 키 암호 방식","path":"crypto","md":"","preview":true,"sub":[],"img":"/assets/study/crypto/https.png","snippet":"그린 그림인지 모르겠지만 가장 쉽게 잘 설명해주신 것 같다.","depth":1},{"label":"NumPy","path":"numpy","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"np.array","depth":1},{"label":"P-value","path":"p-value","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"pandas","path":"pandas","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"PyTorch","path":"pytorch","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}],"img":"/barcode.png","snippet":"궁금해서 찾아본 것, 알고 있었는데 까먹고 있었던 것, 생각 날 때마다 정리해보자.","depth":0},"side_bar":[{"label":"Chi-Square Test","path":"chi-square-test","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"검정은 하나 이상의 카테고리에서 관측된 빈도와 기대되는 빈도가 통계적으로 유의하게 다른지 검증하는 기법으로, 카이 제곱 분포에 기초한 통계적 가설 검정 방법이다.","depth":1},{"label":"HTTPS와 공개 키 암호 방식","path":"crypto","md":"","preview":true,"sub":[],"img":"/assets/study/crypto/https.png","snippet":"그린 그림인지 모르겠지만 가장 쉽게 잘 설명해주신 것 같다.","depth":1},{"label":"NumPy","path":"numpy","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"np.array","depth":1},{"label":"P-value","path":"p-value","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"pandas","path":"pandas","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1},{"label":"PyTorch","path":"pytorch","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}]},{"header":{"label":"토이 프로젝트","path":"03.project","md":"","preview":true,"sub":[{"label":"CNN 기반 형태소 분석기","path":"cnn-morph","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}],"img":"/barcode.png","snippet":"","depth":0},"side_bar":[{"label":"CNN 기반 형태소 분석기","path":"cnn-morph","md":"","preview":true,"sub":[],"img":"/barcode.png","snippet":"","depth":1}]}],"post":"# Coin Tossing (동전 던지기)\r\n\r\n\u003e 동전을 던졌을 때, 앞면이 나올 확률을 데이터에 기반하여 추정해보자\r\n\r\n\u003cimg width=\"180\" src=\"/assets/research/bayesian-inference/coin-tossing/coin-tossing.jpg\" /\u003e\r\n\r\n동전을 던졌을 때, 앞면이 나올 확률은 얼마일까? 우리는 경험적으로 앞면이 나올 확률은 $$\\cfrac 1 2$$이라고 알고 있다.\r\n\r\n여기서 경험적으로 알고 있다라는 것은 데이터에 기반한 것이다라고 생각할 수 있고, 이것은 분명 많은 관측치(Observation)를 통해서 추정해 낸 것일 것이다. 이러한 활동이 사실 기계 학습(Machine Learning)에서 하는 것과 정확하게 일치한다고 할 수 있다.\r\n\r\n다시 본론으로 돌아와서, 다음의 상황을 가정해 보자.\r\n\r\n동전 한 개가 주어져 있고, 동전을 던졌을 때, 동전의 앞면이 나올 확률 $$P(H)$$이 얼마일 지 추정해 보고 싶다. 이를 위해서는 먼저 주어져 있는 동전을 여러번 던져보는 시뮬레이션?이 필요하다.\r\n\r\n예를 들어 동전을 3번 던져 보고 다음과 같은 결과를 얻었다고 하자. 이때 각 시행은 i.i.d. (independent and identically distributed)라고 가정한다.\r\n\r\n$$\r\n\\begin{aligned}\r\nH, H, T\r\n\\end{aligned}\r\n$$\r\n\r\n- $$H$$: 동전 앞면\r\n- $$T$$: 동전 뒷면\r\n\r\n위의 관측치들을 토대로, 일반적으로는 동전 앞면이 나올 확률은 $$P(H) = \\cfrac 2 3$$ 라고 판단할 수 있다. (물론 동전 던지기 시행 횟수가 3번은 매우 적은 숫자이기는 하다.)\r\n\r\n\u003e 위와 같은 해석이 앞으로 설명할 Maximum Likelihood Estimation 방식이라고 할 수 있다.\r\n\r\n이것을 좀 더 formal하게 설명 해 본다면,\r\n\r\n$$\r\n\\begin{aligned}\r\nP(H) \u0026= \\mu \\\\ P(T) \u0026= 1-\\mu\r\n\\end{aligned}\r\n$$\r\n\r\n동전 앞/뒤면이 나올 확률을 각 각 위와 같이 표현할 수 있고, 이때 이 확률 분포는 베르누이 분포(Bernoulli Distribution)를 따른다고 볼 수 있다. 즉, 동전을 던졌을 때 나오는 관측값(ex: $$H, H, T$$) 들은 베르누이 분포로 부터의 샘플이라고 생각할 수 있다.\r\n\r\n따라서, 동전 던지기의 반복된 시행으로부터 얻은 데이터 $$D = \\lbrace x_1, x_2, ... x_N \\rbrace$$, $$x_i=1$$(앞면) 또는 0(뒷면) 라고 할 때,\r\n\r\n데이터의 Likelihood는 다음과 같이 계산된다.\r\n\r\n$$\r\n\\begin{aligned}\r\nP(D|\\mu)\r\n=\r\n\\displaystyle\\prod_{n=1}^{N} p(x_n|\\mu)\r\n=\r\n\\displaystyle\\prod_{n=1}^{N} \\mu^{x_n}(1-\\mu)^{1-x_n}\r\n\\end{aligned}\r\n$$\r\n\r\n\u003cfigcaption align=\"center\"\u003e\r\n  \u003cb\u003e식 1: Likelihood\u003c/b\u003e\r\n\u003c/figcaption\u003e\r\n\r\n위 식을 좀 더 고민해 볼 필요가 있는게, 지금 내가 가지고 있는 \"동전\"이 얼마나 앞면을 잘 나오게 하는 동전인가에 대한 모델 관점에서 바라본다면,\r\n\"동전 모델\"을 설명하는 중요한 파라미터는 베르누이 분포의 파라미터인 $$\\mu$$라고 할 수 있다.\r\n\r\n즉, 기계학습의 관점에서는 주어진 데이터($$D$$)를 통해서 모델의 파라미터인 $$\\mu$$를 찾는 것이 목표라고 할 수 있다.\r\n\r\n이때, 모델 파라미터를 찾는 접근 방식을 다음의 세가지로 구분 할 수 있는데,\r\n\r\n1. Maximum Likelihood Estimation (MLE)\r\n2. Maximum a Posteriori (MAP)\r\n3. Bayesian Inference\r\n\r\n하나씩 어떤 특성이 있는지 알아보도록 하겠다.\r\n\r\n## Maximum Likelihood Estimation (MLE)\r\n\r\n지금 설명하는 MLE 방식은, 대부분의 전통적인 기계학습 모델 뿐만 아니라, 현재 많이 쓰이고 있는 뉴럴 네트워크 모델의 weight 혹은 parameter 값을 구하는데 사용되는 가장 일반적인 방법이다.\r\n\r\n위 동전 던지기 상황에서 Maximum Likelihood Estimation 방식으로 파라미터를 추정해 본다면, 말 그대로 위 식 1 likehood를 최대로 하는 $$\\mu$$를 찾는 문제가 된다.\r\n\r\n$$\r\n\\begin{aligned}\r\n\\mu_{MLE} = \\argmax_{\\mu} P(D|\\mu)\r\n\\end{aligned}\r\n$$\r\n\r\n이는 식 1에 로그를 취하고,\r\n\r\n$$\r\n\\begin{aligned}\r\n\\ln P(D|\\mu)\r\n=\r\n\\displaystyle\\sum_{n=1}^{N} \\ln \\mu + (1-x_n) \\ln(1-\\mu)\r\n\\end{aligned}\r\n$$\r\n\r\n$$\\mu$$에 대한 미분값이 0인 $$\\mu$$값(극대값)을 찾는 방식을 통해 다음과 같이 계산 할 수 있다.\r\n\r\n$$\r\n\\begin{aligned}\r\n\\cfrac d {d\\mu} \\ln P(D|\\mu)\r\n\u0026=\r\n\\displaystyle\\sum_{n=1}^{N} x_n \\cfrac 1 \\mu - (1-x_n) \\cfrac 1 {1-\\mu}\r\n\r\n\\\\ \u0026=\r\n\\cfrac 1 \\mu h - \\cfrac 1 {1-\\mu} t = 0\r\n\r\n\\end{aligned}\r\n$$\r\n\r\n따라서, MLE 방식으로 구한 $$\\mu$$ 값은 아래와 같다.\r\n\r\n$$\r\n\\begin{aligned}\r\n\\mu_{MLE} = \\cfrac h {t+h}\r\n\\end{aligned}\r\n$$\r\n\r\n결과적으로 MLE 방식으로 앞서 동전 던지기의 상황에 대한 파라미터 $$\\mu$$를 추정한다면, 앞면이 나온 횟수 $$h=2$$, 뒷면이 나온 횟수 $$t=1$$ 이기 때문에\r\n\r\n$$\r\n\\begin{aligned}\r\nP(H) = \\mu = \\cfrac 2 3\r\n\\end{aligned}\r\n$$\r\n\r\n이 되고, 이것은 맨 처음 가장 상식적으로? 동전의 앞면이 나올 확률을 예측한 것과 동일한 것을 알 수 있다.\r\n\r\n## Maximum a Posteriori (MAP)\r\n\r\n위 MLE 방식에는 맹점이 있다. 만약 동전을 여러번 던졌는데 그 결과가 아래와 같다면 어떨까?\r\n\r\n$$\r\n\\begin{aligned}\r\nT, T, T\r\n\\end{aligned}\r\n$$\r\n\r\n이런 상황이 발생한다면, MLE 방식으로 동전 앞면이 나올 확률, $$\\mu$$를 추정했을때는 0 이 될 것이다.\r\n이는 주어진 데이터의 불완정성으로 인해 모델 학습 과정에서 overfitting을 발생 시킬 소지가 있다는 것이다.\r\n\r\n이후 설명 할 MAP, 그리고 Bayesian 방식의 모델 파라미터 추정 방식은 이러한 문제를 방지하면서 좀 더 robust한 모델을 학습 하기 위한 철학이라고 생각하면 된다.\r\n\r\n\u003e 사실 데이터가 충분히 많을 경우 위와 같은 문제는 거의 없다고 봐도 되지만, 현실 문제에 있어서 모든 현상을 완벽하게 설명하는 모델을 만들기 어렵고, 데이터 관점에서도 학습을 위해 구축되어 있는 데이터는 실제 우주에 존재하는 모든 관측 가능한 샘플 집합의 극히 일부분임을 감안할 때, 개인적으로는 가능하기만 하다면 Bayesian 방식의 접근법이 합리적이라고 생각한다.\r\n\r\nMAP 방식은 MLE 방식에 비해 조금 더 Bayesian스러운 방식이다.\r\n\r\n$$\\mu$$를 학습하기 위해 다음과 같은 식을 생각해보자.\r\n\r\n$$\r\n\\begin{aligned}\r\nPosterior \u0026= \\cfrac {Likelihood \\times Prior} {Evidence}\r\n\r\n\\\\\r\n\r\nP(\\mu|D)\r\n\u0026=\r\n\\cfrac {P(D|\\mu)P(\\mu)} {P(D)}\r\n\r\n\\\\ \u0026\\propto\r\nP(D|\\mu)P(\\mu)\r\n\r\n\\end{aligned}\r\n$$\r\n\r\n\u003cfigcaption align=\"center\"\u003e\r\n  \u003cb\u003e식 2: Bayes' Rule\u003c/b\u003e\r\n\u003c/figcaption\u003e\r\n\r\n결론을 먼저 얘기하자면,\r\n\r\nMAP는 $$P(\\mu|D)$$, 즉 데이터 $$D$$가 주어졌을 때, 가장 그럴듯한 $$\\mu$$를 찾는 것을 목표로 하는 것이고, MAP에서는 point estimates, 다시 말하면 $$P(\\mu|D)$$의 극대값을 찾는 것을 말한다.\r\n\r\n$$\r\n\\begin{aligned}\r\n\\mu_{MAP} = \\argmax_{\\mu} P(\\mu|D)\r\n\\end{aligned}\r\n$$\r\n\r\n이때 $$P(\\mu|D)$$를 $$\\mu$$에 대한 사후 확률 분포(Posterior)라 하고, 이것은 식 2에서 처럼 베이즈 정리에 따라 가능도(Likelihood)와 사전 확률 분포(Prior)의 곱으로 표현할 수 있다.\r\n\r\n동전 던지기 상황에서 위 식을 적용한다면,\r\n\r\n$$P(D|\\mu)$$는 위 식 1 Likehood를, $$P(\\mu)$$는 베타 분포(Beta Distribution)를 사용하여 다음과 같이 정리할 수 있다.\r\n\r\n\u003e 베르누이 분포의 conjugate prior인 베타분포를 이용하면 계산이 간편해 진다.\r\n\r\n$$\r\n\\begin{aligned}\r\nP(\\mu|D)\r\n\u0026\\propto\r\nP(D|\\mu)P(\\mu)\r\n\\\\ \u0026\\propto\r\n\\displaystyle\\prod_{n=1}^{N} \\mu^{x_n}(1-\\mu)^{1-x_n} \\cdot \\mu^{\\alpha-1}(1-\\mu)^{\\beta-1}\r\n\\\\ \u0026\\propto\r\n\\mu^h(1-\\mu)^{t} \\cdot \\mu^{\\alpha-1}(1-\\mu)^{\\beta-1}\r\n\\\\ \u0026\\propto\r\n\\mu^{h+\\alpha-1}(1-\\mu)^{t+\\beta-1}\r\n\\end{aligned}\r\n$$\r\n\r\n\u003cfigcaption align=\"center\"\u003e\r\n  \u003cb\u003e식 3: 동전 앞면이 나올 확률에 대한 사후 확률 분포\u003c/b\u003e\r\n\u003c/figcaption\u003e\r\n\r\n마찬가지로, \\mu의 극대값을 구하기위해 $$P(\\mu|D)$$ 식의 $$\\mu$$에 대한 미분값을 0으로 하여 계산하게 되면, 아래와 같은 결과를 얻을 수 있다.\r\n\r\n$$\r\n\\begin{aligned}\r\n\\mu_{MAP} = \\cfrac {h+\\alpha-1} {h+t+\\alpha+\\beta-2}\r\n\\end{aligned}\r\n$$\r\n\r\n이때, 동전 시행 횟수가 무한히 많아진다면, 위 식에서 상대적으로 작은 값인 $$\\alpha$$와 $$\\beta$$의 영향이 거의 없어지기 때문에, 위 값은 위 MLE 방식의 파라미터 추정값과 동일하게 된다고 볼 수 있다. MAP에서 사전 확률 분포를 Uniform Distribution으로 설정하면 이것은 MLE와 같은 결과를 얻을 수 있다.\r\n\r\n## Bayesian Inference\r\n\r\n위 MAP 방식은 어느정도 Bayesian 방식의 철학을 담고 있다고 하였다. 하지만 MAP로 추정한 파라미터 값 역시 point estimates이기 때문에 한계를 가진다.\r\n\r\n진정한 Bayesian 관점으로 파라미터를 추정하기 위해서는 더 많은 정보를 담고 있는 $$P(\\mu|D)$$ 분포를 이용하여 사후 확률 분포의 평균(Posterior mean)을 구하는 것이 필요하다. 즉, 모든 가능한 파라미터 셋팅에 대해 평균을 취하는 것이 가장 이상적인 선택이라는 뜻이다.\r\n\r\n$$\r\n\\begin{aligned}\r\n\\mathbb{E}(\\mu|D) = \\displaystyle\\int \\mu P(\\mu|D) d\\mu\r\n\\end{aligned}\r\n$$\r\n\r\n일반적으로 위 적분은 계산하기가 어려운 경우가 많아 특별한 inference 방식을 사용해야한다.\r\n\r\n\u003e Gibbs Sampling 혹은 Variational Inference가 대표적이다.\r\n\r\n하지만, 위 식의 경우에는 굉장히 간단한 방법으로 계산을 할 수가 있는데, 앞서 설명 했듯이 $$P(\\mu|D)$$는 Likelihood가 베르누이 분포, Prior가 베타 분포로 형성된 Posterior 이다.\r\n\r\n베르누이 분포의 conjugate prior인 베타분포를 Prior로 둔 이유가 여기에 있는데, Likelihood와 Prior의 곱으로 표현되는 Posterior 역시 베타 분포로 그 형태가 동일하게 되기 때문에, $$P(\\mu|D)$$는 파라미터를 $$\\alpha+h$$, $$\\beta+t$$로 가지는 베타 분포이고, 이 베타분포의 기댓값이 바로 앞서 구하려고 했던 Posterior mean이라고 볼 수 있다.\r\n\r\n$$\r\n\\begin{aligned}\r\n\\mathbb{E}(\\mu|D)\r\n\u0026= \\cfrac {\\alpha+h} {\\alpha+\\beta+h+t}\r\n\\\\ \u0026= \\cfrac {\\alpha+h} {\\alpha+\\beta+N}\r\n\\end{aligned}\r\n$$\r\n","path":"00.research/bayesian-inference/coin-tossing","visitors":{"today":0,"total":55},"revalidate":60},"__N_SSG":true},"page":"/[[...path]]","query":{"path":["00.research","bayesian-inference","coin-tossing"]},"buildId":"ou1GuEhRbVUycYWZlNpww","assetPrefix":"/blog","isFallback":false,"gsp":true,"appGip":true,"scriptLoader":[]}</script></body><link rel="preload" href="/blog/_next/static/css/990b0c1dfde9f715.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/990b0c1dfde9f715.css" data-n-g=""/><link rel="preload" href="/blog/_next/static/css/c4f4fac9cc925550.css" as="style"/><link rel="stylesheet" href="/blog/_next/static/css/c4f4fac9cc925550.css" data-n-p=""/><noscript data-n-css=""></noscript><script defer="" nomodule="" src="/blog/_next/static/chunks/polyfills-5cd94c89d3acac5f.js"></script><script src="/blog/_next/static/chunks/webpack-5f931f2fb596b881.js" defer=""></script><script src="/blog/_next/static/chunks/framework-bb5c596eafb42b22.js" defer=""></script><script src="/blog/_next/static/chunks/main-9ce13651fe56a6de.js" defer=""></script><script src="/blog/_next/static/chunks/pages/_app-6af7068010ddd551.js" defer=""></script><script src="/blog/_next/static/chunks/175675d1-f160d4a5df49f5d3.js" defer=""></script><script src="/blog/_next/static/chunks/pages/%5B%5B...path%5D%5D-bbbca7f62f73efb0.js" defer=""></script><script src="/blog/_next/static/ou1GuEhRbVUycYWZlNpww/_buildManifest.js" defer=""></script><script src="/blog/_next/static/ou1GuEhRbVUycYWZlNpww/_ssgManifest.js" defer=""></script><script src="/blog/_next/static/ou1GuEhRbVUycYWZlNpww/_middlewareManifest.js" defer=""></script><style data-styled="" data-styled-version="5.3.5">.UrsbL{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;padding:10px 30px;-webkit-text-decoration:none;text-decoration:none;color:black;-webkit-tap-highlight-color:transparent;overflow:hidden;text-overflow:ellipsis;white-space:nowrap;}/*!sc*/
.UrsbL:focus{outline:none;}/*!sc*/
data-styled.g2[id="StyledLink__AnchorTag-sc-1001dlb-1"]{content:"UrsbL,"}/*!sc*/
.dYSPYo{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;width:100%;}/*!sc*/
data-styled.g3[id="Header__Container-sc-13fiemu-0"]{content:"dYSPYo,"}/*!sc*/
.hGyWUd{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;width:220px;}/*!sc*/
data-styled.g4[id="Header__Left-sc-13fiemu-1"]{content:"hGyWUd,"}/*!sc*/
.edgYtU{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;width:calc(100% - 220px);overflow:none;}/*!sc*/
data-styled.g5[id="Header__Middle-sc-13fiemu-2"]{content:"edgYtU,"}/*!sc*/
.eJxZWF{position:absolute;top:0;right:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:60px;height:100%;background-color:white;}/*!sc*/
data-styled.g7[id="Header__Right-sc-13fiemu-4"]{content:"eJxZWF,"}/*!sc*/
.fcVijG{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin-left:10px;width:40px;height:40px;cursor:pointer;border:1px solid #d3d3d3;border-radius:50%;-webkit-tap-highlight-color:transparent;font-size:1.2rem;}/*!sc*/
@media (hover:hover){.fcVijG:hover{background:#d3d3d3;}}/*!sc*/
data-styled.g8[id="Header__MenuButtonItem-sc-13fiemu-5"]{content:"fcVijG,"}/*!sc*/
.ekaHDe{margin-left:6px;height:40px;cursor:pointer;text-align:center;-webkit-tap-highlight-color:transparent;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}/*!sc*/
data-styled.g9[id="Header__LogoItem-sc-13fiemu-6"]{content:"ekaHDe,"}/*!sc*/
.eqLAjq{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;margin:4px;height:30px;cursor:pointer;border-radius:12px;-webkit-user-select:none;-moz-user-select:none;-ms-user-select:none;user-select:none;}/*!sc*/
@media (hover:hover){.eqLAjq:hover{background:#d3d3d3;}}/*!sc*/
data-styled.g12[id="Header__HeaderItem-sc-13fiemu-9"]{content:"eqLAjq,"}/*!sc*/
.hhsZYw{position:absolute;z-index:1000;top:0;left:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;height:100%;height:100%;width:0px;-webkit-transition:width 0.2s ease-out;transition:width 0.2s ease-out;overflow-y:overlay;}/*!sc*/
.hhsZYw::-webkit-scrollbar{width:4px;}/*!sc*/
.hhsZYw::-webkit-scrollbar-track{background:#d3d3d3;}/*!sc*/
.hhsZYw::-webkit-scrollbar-thumb{background:grey;}/*!sc*/
.hhsZYw::-webkit-scrollbar-thumb:hover{background:black;}/*!sc*/
data-styled.g14[id="SideBar__Container-sc-3wui5d-0"]{content:"hhsZYw,"}/*!sc*/
*{box-sizing:border-box;}/*!sc*/
html,body{margin:0;padding:0;font-size:16px;overflow:hidden;}/*!sc*/
data-styled.g22[id="sc-global-jEDTxm1"]{content:"sc-global-jEDTxm1,"}/*!sc*/
.krcVEB{position:absolute;top:0;left:0;right:0;bottom:0;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;height:100%;overflow:hidden;}/*!sc*/
data-styled.g23[id="MainApp__GlobalContainer-sc-1rpcipa-0"]{content:"krcVEB,"}/*!sc*/
.ewsZwM{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;height:100%;}/*!sc*/
data-styled.g24[id="MainApp__Container-sc-1rpcipa-1"]{content:"ewsZwM,"}/*!sc*/
.fbkGGC{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;height:50px;border-bottom:1px solid #d3d3d3;}/*!sc*/
data-styled.g25[id="MainApp__HeaderContainer-sc-1rpcipa-2"]{content:"fbkGGC,"}/*!sc*/
.dfELKT{position:relative;display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;-webkit-align-items:center;-webkit-box-align:center;-ms-flex-align:center;align-items:center;width:100%;height:calc(100% - 50px);}/*!sc*/
data-styled.g26[id="MainApp__ContentContainer-sc-1rpcipa-3"]{content:"dfELKT,"}/*!sc*/
.cpybIA{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;padding:0 20px;width:100%;max-width:800px;}/*!sc*/
data-styled.g36[id="MarkDownComponent__MarkDownContainer-sc-k3onaj-0"]{content:"cpybIA,"}/*!sc*/
.gjyNUS{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-flex-direction:column;-ms-flex-direction:column;flex-direction:column;width:100%;height:100%;}/*!sc*/
data-styled.g37[id="path__Container-sc-ky1y75-0"]{content:"gjyNUS,"}/*!sc*/
.fQsNxc{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:end;-webkit-justify-content:flex-end;-ms-flex-pack:end;justify-content:flex-end;width:100%;height:24px;font-size:12px;padding:2px;padding-right:20px;}/*!sc*/
data-styled.g38[id="path__TopContainer-sc-ky1y75-1"]{content:"fQsNxc,"}/*!sc*/
.grtMOo{display:-webkit-box;display:-webkit-flex;display:-ms-flexbox;display:flex;-webkit-box-pack:center;-webkit-justify-content:center;-ms-flex-pack:center;justify-content:center;overflow-y:overlay;width:100%;height:calc(100% - 24px);overflow-y:overlay;}/*!sc*/
.grtMOo::-webkit-scrollbar{width:4px;}/*!sc*/
.grtMOo::-webkit-scrollbar-track{background:#d3d3d3;}/*!sc*/
.grtMOo::-webkit-scrollbar-thumb{background:grey;}/*!sc*/
.grtMOo::-webkit-scrollbar-thumb:hover{background:black;}/*!sc*/
data-styled.g39[id="path__BottomContainer-sc-ky1y75-2"]{content:"grtMOo,"}/*!sc*/
</style></head></html>